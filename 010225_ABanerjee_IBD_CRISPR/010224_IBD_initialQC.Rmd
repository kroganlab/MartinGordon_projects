---
title: "010224_IBD_initalQC"
author: "Martin Gordon"
date: "2025-01-02"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## look at the IBD counts data; how does the normalization look?
Read in the necessary packages

IBD initial QC; this was on the CAT sequencing data only..
Need to look at the Gladstone or combined sequencing data

```{r}
library(data.table)
library(ggplot2)
library(magrittr)
library(ggrepel)
library(stringr)
library(ComplexHeatmap)
library(circlize)
library(MSstats)
library(viridis)
library(ggbeeswarm)
library(RColorBrewer)
library(hrbrthemes) # visually nice set of themes
library(patchwork)
library(showtext)


source("../../utils/bp_utils/MSstats_Helper_Functions.R")
source("../../utils/bp_utils/ManageScriptData.R")
source ("../../utils/bp_utils/MSstats_V4_Functions.R")
source ("../../utils/bp_utils/UniprotIDMapping.R") #uniprot to gene id mapping
source ("../../utils/bp_utils/enrichmentTestFunctions.R")
source ("../../utils/bp_utils/MSstats_V4_Functions.R")


# for generating the scatterplots
source("../../utils/mg_utils/r_utils/plottingHelperFunctions.R")


# my mageck functions for normalizing
# this set of mageck functions is messing up my matrix generation... why is it calling another (maybe base?) as.matrix function?
#source("../../utils/mg_utils/r_utils/MAGECK_Functions.R")

# function to cluster w NA values
clusterWNA <-  function(mat, na.value=0,...){
  
  mat[is.na(mat)] <- na.value
  return(hclust(dist(mat)))
}


#set one
#col.pal <- randomcoloR::distinctColorPalette(k=13)
col.pal <- getQualitativePalette(n=13)

# fonts needed for hrbrthemes
library(extrafont)
font_import()
loadfonts()

# directly from google font
sysfonts::font_add_google("Roboto Condensed")
showtext_auto()
```
First we want to read in the count matrix, look at the count distributions, Number of 0s in each sample, sample-sample correlations etc

```{r}
counts.dt <- fread('data/Package_Alicia_Ronald_9-18-2023/merged_counts.table') %>% 
  melt(id.vars=c('sgRNA', 'gene'), value.name = 'counts')
setnames(counts.dt, old='variable', new='sample')
```
How many guides per gene (per sample)
```{r}
# 4 guides targeting each gene
counts.dt[,.N, by=.(gene,sample)][gene != 'NonTargeting']

# how many genes sampled in total?
# 19114 genes in total recovered...
counts.dt[,.N, by=.(gene)][gene != 'NonTargeting', unique(gene)] %>% length()
```

Look at sample distributions and pw sample correlations 
```{r}
counts.dt[, replicate := gsub('_EXP', '', str_extract(sample, '_EXP[12]'))]
counts.dt[, group := gsub('_EXP[12]', '', sample)]

# rename
counts.dt[group == 'Library_representation', group := 'Library_Representation']
```

Boxplots of the distributions of counts in each of the samples

```{r}
ggplot(counts.dt, aes(x=paste0(group,'.', replicate), y=log2(counts+1), fill=group)) +
  geom_boxplot() +
  scale_fill_ipsum() +
  theme_ipsum_rc(grid = "XY") +
  theme_fill_ipsum()


g <- ggplot(counts.dt, aes(x=paste0(group,'.', replicate), y=log2(counts+1), fill=group)) +
    geom_boxplot() +
   #scale_fill_manual(values=col.pal) +  
    ggtitle(paste0('Raw count distributions')) +
    xlab('sample') +
    scale_fill_ipsum() +
    theme_ipsum_rc(grid = "XY") +
    theme(axis.text.x = element_text(angle=90, size=7),
      panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1))

BackupAsPDF(g, 'rawCounts.boxplot')
```
Look at distributions of non-targeting controls

```{r}
g <- ggplot(counts.dt[gene == 'NonTargeting'], aes(x=paste0(group,'.', replicate), y=log2(counts+1), fill=group)) +
    geom_boxplot() +
   #scale_fill_manual(values=col.pal) +  
    ggtitle(paste0('Non-targeting controls raw count distributions')) +
    xlab('sample') +
    scale_fill_ipsum() +
    theme_ipsum_rc(grid = "XY") +
    theme(axis.text.x = element_text(angle=90, size=7),
      panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1))

g

BackupAsPDF(g, 'sgCtrls.rawCounts.boxplot')

hist(counts.dt[gene == 'NonTargeting' & sample == 'High_CARD9_EXP2']$count)
```
Number of 0 counts in each sample
```{r}
# zero counts in the
g <- ggplot(counts.dt[counts == 0,.N, by=.(sample, group, replicate)], aes(x=paste0(group,'.', replicate), y=N, fill=group)) +
    geom_bar(stat='Identity') +
   #scale_fill_manual(values=col.pal) +  
    ggtitle(paste0('Number of 0 count guides')) +
    xlab('sample') +
    scale_fill_ipsum() +
    theme_ipsum_rc(grid = "XY") +
    theme(axis.text.x = element_text(angle=90, size=7),
      panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1))

g
BackupAsPDF(g, 'nZeroCounts.barplot')
```

Proportion of guides that are 0 counts in each sample

```{r}
# count the number of rows per sample
counts.dt[, nGuides:=.N,  by=sample] # so I guess this has been filled with zeros?
summary.dt <- counts.dt[counts == 0,  .N, by=.(sample, group, replicate, nGuides)]

summary.dt[, propZero := N/nGuides]

g <- ggplot(summary.dt, aes(x=paste0(group,'.', replicate), y=propZero, fill=group)) +
    geom_bar(stat='Identity') +
   #scale_fill_manual(values=col.pal) +  
    ggtitle(paste0('Proportion of 0 count guides')) +
    xlab('sample') +
    ylab('') +
    scale_fill_ipsum() +
    theme_ipsum_rc(grid = "XY") +
    theme(axis.text.x = element_text(angle=90, size=7),
      panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1))

g
BackupAsPDF(g, 'proportionOfZeroCounts.barplot', format='png')
```
Number of 0 counts in non-targeting guides.. huge number 

```{r}
g <- ggplot(counts.dt[gene == 'NonTargeting' & counts == 0, .N, by=.(sample, group, replicate)], aes(x=paste0(group,'.', replicate), y=N, fill=group)) +
    geom_bar(stat='Identity') +
   #scale_fill_manual(values=col.pal) +  
    ggtitle(paste0('Number of 0 count non-targeting (control) guides')) +
    xlab('sample') +
    scale_fill_ipsum() +
    theme_ipsum_rc(grid = "XY") +
    theme(axis.text.x = element_text(angle=90, size=7),
      panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1))

g
BackupAsPDF(g, 'nZeroCounts.controlGuides.barplot')
```

Total number of reads in each sample

```{r}
g <- ggplot(counts.dt[, .(seqDepth = sum(counts, na.rm=T)), by=.(group, replicate)], aes(x=paste0(group, replicate), y=log2(seqDepth), color=group)) +
    geom_point()+
   #scale_fill_manual(values=col.pal) +  
    ggtitle(paste0('Sample sequencing depth')) +
    xlab('sample') +
    scale_y_continuous(breaks=seq(14,23, 1), labels=seq(14,23, 1)) +
    ylab('log2 Total Reads') +
    scale_color_ipsum() +
    theme_ipsum_rc(grid = "XY") +
    theme(axis.text.x = element_text(angle=90, size=7),
      panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1))

g
BackupAsPDF(g, 'Sample.seqDepth.dotplot', format='png')
```
Look at count distribution (non-normalized)

```{r}
g <- ggplot(counts.dt, aes(x=log2(counts+1), alpha=0.4,fill=sample)) +
  geom_density() +
  #coord_cartesian(xlim=c(0,100)) +
  ggtitle(paste0('Guide count distribution')) +
  scale_fill_ipsum() +
  facet_wrap(~group, scales='free_x') +
  theme_ipsum_rc(grid = "XY") +
  theme(axis.text.x = element_text(angle=90, size=7),
        panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1)) +
  guides(alpha='none')

g
BackupAsPDF(g, 'guideCounts.density')


# clearly more 0s in the second experiment 
g <- ggplot(counts.dt, aes(x=log2(counts+1), alpha=0.4,fill=sample)) +
  geom_density() +
  #coord_cartesian(xlim=c(0,100)) +
  ggtitle(paste0('Guide count distribution')) +
  scale_fill_ipsum() +
 # facet_wrap(~group, scales='free_x') +
  theme_ipsum_rc(grid = "XY") +
  theme(axis.text.x = element_text(angle=90, size=7),
        panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1)) +
  guides(alpha='none')

g
BackupAsPDF(g, 'guideCounts.combined.density')
```
Counts not normalized. Lets normalize before the DE testing
Will try normalize using the non-targeting controls. Pull these out and prepare the non-targeting controls for analysis

```{r}
ctrl.guides.dt <- counts.dt[gene == 'NonTargeting',.(sgRNA)] %>%  unique()
fwrite(ctrl.guides.dt, col.names = F,  ScriptAndDatedFileName('sgControlGuides.txt'))
```



*Todo*

Run the PW comparisons and look at the output
Looking at the comparisons onf the sgcontorl normalized groups
```{r}
# look at the gene level info
card9H.dt <- fread('output/totalCountNormMethod/High_CARD9-Library_Representation.gene_summary.txt')
card9L.dt <- fread('output/totalCountNormMethod/Low_CARD9-Library_Representation.gene_summary.txt')

# read in the high vs low comparions
card9HvsL.dt <- fread('output/totalCountNormMethod/High_CARD9-Low_CARD9.gene_summary.txt')
```
look at volcano plots of these two comparisons
To take a pvalue, we will need to adjust the 

```{r}
card9H.dt[, LFC := `pos|lfc`]
card9H.dt[, pvalue := ifelse(sign(`neg|lfc`) == 1, `pos|p-value`, `neg|p-value`)]

card9L.dt[, LFC := `pos|lfc`]
card9L.dt[, pvalue := ifelse(sign(`neg|lfc`) == 1, `pos|p-value`, `neg|p-value`)]

card9H.dt[, LFC := `pos|lfc`]
card9H.dt[, pvalue := ifelse(sign(`neg|lfc`) == 1, `pos|p-value`, `neg|p-value`)]

card9HvsL.dt[, LFC := `pos|lfc`]
card9HvsL.dt[, pvalue := ifelse(sign(`neg|lfc`) == 1, `pos|p-value`, `neg|p-value`)]

# sanity check 
card9H.dt[, .(`pos|p-value`, `neg|p-value`, `pos|lfc`, `neg|lfc`, pvalue, LFC)]
card9L.dt[, .(`pos|p-value`, `neg|p-value`, `pos|lfc`, `neg|lfc`, pvalue, LFC)]
card9HvsL.dt[, .(`pos|p-value`, `neg|p-value`, `pos|lfc`, `neg|lfc`, pvalue, LFC)]

card9HvsL.dt[, contrast := 'High_CARD9-Low_CARD9']
card9H.dt[, contrast := 'High_CARD9-Library_Representation']
card9L.dt[, contrast := 'Low_CARD9-Library_Representation']


mageck.dt <- rbind(card9HvsL.dt, card9H.dt, card9L.dt) %>% 
  as.data.table()

mageck.dt[, p.adj := p.adjust(pvalue, method='BH'), by=contrast]

# drop the non-targeting set; dont want this impacting the FDR
clean.dt <- mageck.dt[id != 'NonTargeting']
# padj 
clean.dt[, p.adj := p.adjust(pvalue, method='BH'), by=contrast]


# sig label... nothing passess significance
clean.dt[, sig := 'not']
clean.dt[abs(LFC) >= 1 & pvalue < 0.005, sig := ifelse(LFC > 0, 'up', 'down')]
```

Ok, generate volcanoplots of the two comparisons; do our hits we are interested in lie near the top?

```{r}
clean.dt %>% colnames()
lapply(contrasts.oi, function(x){
  
  g <- ggplot(clean.dt[contrast==x,], aes(x=LFC, y=-log10(pvalue), color=sig, label=id)) +
  geom_point(size=0.7) +
  geom_vline(xintercept = c(-1,1), linetype=4, alpha=0.4) +
  geom_hline(yintercept = -log10(0.005), linetype=4, alpha=0.4) +
  geom_text_repel(data=clean.dt[sig != 'not' & contrast==x,], segment.linetype=1, segment.alpha=0.4, size=2, max.overlaps = 20) +
  scale_color_manual(values=c('not'='grey', 'up'=col.pal[2], 'down'=col.pal[1])) +
  ggtitle(x) +
  ylab(expression(paste(-log10, ' pvalue'))) +
  theme_ipsum_rc(grid = "XY") +
  theme(axis.text.x = element_text(angle=90, size=7),
        panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1)) +
  guides(Label = 'None')
  g
  BackupAsPDF(g, paste0(x,'.pval0.005.volcanoplot'), format = 'png')
})
```
For volcanoplots, see where Adrians list of hits for low vs high fall

```{r}
ap.genes <- 'CARD9 LUC7L3 TSC2 IRF8 PCYT2 HNRNPU EXOSC6 POLR3H SNRNP40 NELFB PRMT1 ARMC7 USP7 MAU2 MIS18A INTS3 TUT1 POLR2L EXOSC2 ADIPOR2 VHL SMC1A KDM8 CLNS1A GEMIN4 DKC1 MED12 SLC35B1 NHP2 RPN1 DHFR FBXO11 CTR9 GNB1L DNAJC17 EP300 PKMYT1 TMEM258 TCEB2 LSG1 EIF6 MED6 BCL2 RAD9A NUS1 RPTOR SUPT4H1 RCE1 RANGAP1 DRAP1 TRAPPC1 ERCC2 GEMIN8 PREB POLR3E EEF1G SKIV2L2 EXOSC4 PAPOLA GPN2 VPS52 SAMD4B VPS53 HAUS5 IPPK SYS1 CTDNEP1 CRCP WDR61 NOP14 ECT2 ALG2 SNAPC5 UROD EXOSC9 CARS RTFDC1 ZCRB1 POLR1D ELL SRSF11 RFC3 LSM7 RPL9 LSM5 ALYREF SNAPC4 NSA2 RSL24D1 POLR3K COG8 LSM8 PTMA STAG2 DDX51 PPP1R11 IPO13 MEF2D RFC2 GNL3L TELO2 CDS2 SMARCE1 C15orf41 SETD1A WDR18 TRAPPC5 DHX16 PRMT5 RNMT C14orf80 DCAF15 UBL5 NOP16 YKT6 DDX41 BUB3 TFAP4 VMP1 SFSWAP DYNLL1 ITPK1 RPL31 NOL10 DNAJC8 RABGGTA INTS4 WDR82 TTC1 COG4 DDX20 CTSL PELP1 AP2S1 HSPA5 URI1 SS18L2 PWP2 CCDC84 HSPA13 MED16 VPS51 FTSJ3 KBTBD4 OSBP EFTUD2 ELAC2 EXOSC3 AXIN1 CAND1 PRPF38B ST14 GALR3 IMP4 FIP1L1 DDOST DHODH NELFA SNUPN SETD1B LSM12 EIF2S3 CCDC86 LOC101060389 NCOA2 XRCC6 BTF3 RBM33 DYNLRB1 COPS6 PFN1 SLC6A20 CBFB MARCH5 POLE2 SMARCB1 SYMPK AGAP4 PSMB2 XPO1 SART3 CPSF3L RPL11 NOB1 NSL1 CSNK1A1 POLR3F ECD CENPL TUBB'

ap.genes <- strsplit(ap.genes, ' ')[[1]]
```

```{r}
clean.dt[, lab := sig ]
clean.dt[id %in% ap.genes, lab := 'APelin hit']
clean.dt[, lab := factor(lab, levels=c("not", "down", "up","APelin hit"))]


#fwrite(clean.dt, ScriptAndDatedFileName('mageck.pwcomparisons.firstPass.csv'))
clean.dt <-  fread('~/Documents/projects/010225_ABanerjee_IBD_CRISPR/010224_IBD_initialQC_data/2025_01_03_mageck.pwcomparisons.firstPass.csv')
```


```{r}
lapply(contrasts.oi, function(x){
  
  g <- ggplot(clean.dt[contrast==x,], aes(x=LFC, y=-log10(pvalue), color=lab, label=id, order=lab)) +
  geom_point(data=clean.dt[contrast==x & lab != 'APelin hit',], size=0.7) +
  geom_point(data=clean.dt[contrast==x & lab == 'APelin hit',], size=0.7) +
  geom_vline(xintercept = c(-1,1), linetype=4, alpha=0.4) +
  geom_hline(yintercept = -log10(0.005), linetype=4, alpha=0.4) +
  geom_text_repel(data=clean.dt[sig != 'not' & contrast==x,], segment.linetype=1, segment.alpha=0.4, size=2, max.overlaps = 20) +
  scale_color_manual(values=c('not'='grey', 'up'=col.pal[2], 'down'=col.pal[1], 'APelin hit'=col.pal[3])) +
  ggtitle(x) +
  ylab(expression(paste(-log10, ' pvalue'))) +
  theme_ipsum_rc(grid = "XY") +
  theme(axis.text.x = element_text(angle=90, size=7),
        panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1)) +
  guides(Label = 'None')
  g
  BackupAsPDF(g, paste0(x,'.pval0.005.APelinHitslabelled.volcanoplot'), format = 'png')
})
```
Run GSEA enrichment on the ranked list of genes (signed pvalue maybe?)

```{r}
library(fgsea)

# conver tthe GO geneset to named list
go.list <- as.character(gmt.hs.go.bp$gene) %>% 
split(., gmt.hs.go.bp$ont)

# convert KEGG to a named list 
kegg.list <- as.character(gmt.hs.kegg$gene) %>% 
split(., gmt.hs.kegg$ont)

kegg.fgsea <- lapply(unique(clean.dt$contrast), function(x){
  
  message('subsetting to ', x,'...')
  subdt <- clean.dt[contrast == x]
  # create a ranked list of genes
  # rank based on pval and LFC
  ranking <-  subdt$LFC * -log10(subdt$pvalue)
  names(ranking) <- subdt$id
  print(ranking[1:10])
  print(names(ranking)[1:10])
  ranking <- sort(ranking, decreasing = T) # sort descending as interested in depletion
  print(ranking[1:10])
  print(names(ranking)[1:10])

  message('Running KEGG GSEA on ', x)
  
  kegg.dt <- fgsea(pathways = kegg.list,
        stats=ranking,
        minSize = 10,
        maxSize = 1000,
        nPermSimple = 100000)
  
  
  kegg.dt <- setDT(kegg.dt)
  kegg.dt[, contrast := x]
  return(kegg.dt)
    
}) %>% rbindlist()

fwrite(kegg.fgsea, ScriptAndDatedFileName('gsea.kegg.csv'))

gobp.fgsea <- lapply(unique(clean.dt$contrast), function(x){
  
  message('subsetting to ', x,'...')
  subdt <- clean.dt[contrast == x]
  # create a ranked list of genes
  # rank based on pval and LFC
  ranking <-  subdt$LFC * -log10(subdt$pvalue)
  names(ranking) <- subdt$id
  print(ranking[1:10])
  print(names(ranking)[1:10])
  ranking <- sort(ranking, decreasing = T) # sort descending as interested in depletion
  print(ranking[1:10])
  print(names(ranking)[1:10])

  message('Running GOBP GSEA on ', x)
  
  gobp.dt <- fgsea(pathways = go.list,
        stats=ranking,
        minSize = 10,
        maxSize = 1000,
        nPermSimple = 100000)
  
  
  gobp.dt <- setDT(gobp.dt)
  gobp.dt[, contrast := x]
  return(gobp.dt)
    
}) %>% rbindlist()

# check out the number of sig hits in each contrast
fwrite(gobp.fgsea, ScriptAndDatedFileName('gsea.GOBP.csv'))
```
Read in the fgsea results and plot for each of the different contrasrs
```{r}
go.bp.enrich.dt <- fread('~/Documents/projects/010225_ABanerjee_IBD_CRISPR/010224_IBD_initialQC_data/2025_01_02_gsea.GOBP.csv')
kegg.enrich.dt <- fread('~/Documents/projects/010225_ABanerjee_IBD_CRISPR/010224_IBD_initialQC_data/2025_01_02_gsea.kegg.csv')

kegg.enrich.dt[padj < 0.1]
go.bp.enrich.dt[padj < 0.05]
```
# plot lollipop charts of the gsea results
```{r}
# get N elements in the geneset size
go.bp.enrich.dt[, leadingEdgeSize := length(unlist(strsplit(leadingEdge, '[|]'))), by=.I]
go.bp.enrich.dt[, geneRatio := leadingEdgeSize/size, by=.I]

g <- ggplot(go.bp.enrich.dt[contrast == 'High_CARD9-Low_CARD9' & padj < 0.05,], aes(x=reorder(pathway,NES), y=NES, size=geneRatio, color=-log10(padj))) +
  geom_point() +
  ggtitle('GO BP High_CARD9-Low_CARD9') +
  xlab('GO BP Pathway') +
  ylab('Normalized Enrichment Score') +
  scale_size_continuous(range = c(1, 5.5)) +
  scale_color_viridis() +
  coord_flip() +
  theme_ipsum_rc(grid = "XY") +
  theme(axis.text.x = element_text(angle=90, size=7),
        axis.text.y = element_text(size=6),
        panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1))
g
BackupAsPDF(g, 'GO.BP.GSEA.dotplot', format='png', dimensions = c(8,8))
```
lollipop chart of the gsea results for KEGG

```{r}
kegg.enrich.dt[, leadingEdgeSize := length(unlist(strsplit(leadingEdge, '[|]'))), by=.I]
kegg.enrich.dt[, geneRatio := leadingEdgeSize/size, by=.I]

g <- ggplot(kegg.enrich.dt[contrast == 'High_CARD9-Low_CARD9' & pval < 0.005,], aes(x=reorder(pathway,NES), y=NES, size=geneRatio, color=-log10(pval))) +
  geom_point() +
  ggtitle('KEGG High_CARD9-Low_CARD9') +
  xlab('KEGG Pathway') +
  ylab('Normalized Enrichment Score') +
  scale_size_continuous(range = c(2, 7)) +
  scale_color_viridis() +
  coord_flip() +
  theme_ipsum_rc(grid = "XY") +
  theme(axis.text.x = element_text(angle=90, size=7),
        axis.text.y = element_text(size=6),
        panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1))

g
BackupAsPDF(g, 'KEGG.GSEA.dotplot', format='png', dimensions = c(8,7))
```
# heatmap of the sig hits (barcode anno for Adrians hits and mine); check to ensure they look decent quality for identification and follow-up screening 
Good way to check the quality of the hits we are recovering

```{r}
counts.mat <- dcast(counts.dt, sgRNA~paste0(group, '.', replicate), value.var = 'counts') %>% 
  as.matrix(rownames = 1)

sigHits <- clean.dt[contrast == 'High_CARD9-Low_CARD9' & sig != 'not', id]
apHits <- clean.dt[contrast == 'High_CARD9-Low_CARD9' & lab == 'APelin hit', id]

guides.oi <- counts.dt[gene %in% c(sigHits, apHits), sgRNA]
# subset to guides belonging to sig list

submat <- counts.mat[rownames(counts.mat) %in% guides.oi,]
submat <- log2(submat +1)

# sweep out the median values and lets see how these two things change; lets see if our hits look decent quality
#submat <- sweep(submat, 1, apply(submat, 1, median, na.rm=T))

hm <- Heatmap(submat, 
        col=viridis(100), 
        name='log2(counts+1)',
        column_split = gsub('.[12]$' ,'', colnames(submat)), 
        border=T,
        column_names_gp = gpar(fontsize=6),
        show_row_names=F)
hm

BackupAsPDF(draw(hm, column_title='Median scaled log-tranformed counts'), 'raw.Log2counts.sigGenes.heatmap', format='png')
```

Lets generate a heatmap of the sample correlations with raw counts.
Clear evidence of batch effect between samples 1 & 2; not sure how normalization will help to low coverage...
Still lets plot heatmaps of the normalized values and see if they bring the conditions into closer alignment
```{r}
# log2 transform for normal distirbution
corMat <- cor(log2(counts.mat+1), method='pearson', use = 'pairwise.complete.obs')

# dendo ordereding
od =  hclust(dist(corMat))$order
corMat = corMat[od, od]


hm <- Heatmap(corMat,
        col=viridis(30, option='A'),
        name='Pearsons r',
        cluster_rows = FALSE, 
        cluster_columns = FALSE,
        column_dend_side = 'bottom',
        rect_gp = gpar(type = "none"),
        column_names_gp = gpar(fontsize=6),
        row_names_gp = gpar(fontsize=6),
	      cell_fun = function(j, i, x, y, w, h, fill) {
		      if(i >= j) {
			      grid.rect(x, y, w, h, gp = gpar(fill = fill, col = fill))
		        grid.text(sprintf("%.2f", corMat[i, j]), x, y, gp = gpar(col='white', fontsize = 7))
		      }
	  })
hm
BackupAsPDF(draw(hm, column_title='Sample correlations (log-transformed counts)'), 'sgRNAnorm.PWCorrelations.heatmap',format='png')

```

look at the sig hits in the RPM mat
```{r}
# RPM mat 
# issue here is as we are using proportions to normalize and as 0 counts are so inflated in a couple of samples, we will 
rpm.mat <- sweep(counts.mat, 2, apply(counts.mat, 2, sum, na.rm=T), FUN='/')  * 1e6

submat <- rpm.mat[rownames(rpm.mat) %in% guides.oi,]
submat <- log2(submat +1)
# sweep out the median values and lets see how these two things change; lets see if our hits look decent quality
#submat <- sweep(submat, 1, apply(submat[, grepl('Low_CARD9', colnames(submat))], 1, median, na.rm=T))

hm <- Heatmap(submat, 
        #col=viridis(100), 
        name='log2(RPM+1)',
        column_split = gsub('.[12]$' ,'', colnames(submat)), 
        border=T,
        column_names_gp = gpar(fontsize=6),
        show_row_names=F)
hm

BackupAsPDF(draw(hm, column_title='RPM log-tranformed counts'), 'RPM.log2counts.sigGenes.heatmap', format='png')
```
Do I try to renormalize using DESeq2 method on the controls? maybe do that first and see how the count distributions look as easier 
Second runs seem unusable to be honest... need to reanalyze. Either recount or just drop rep2 and do the comparisons with a single replicate...

```{r}
source("../../utils/mg_utils/r_utils/MAGECK_Functions.R")

 #DESeq2 method fails on both sample #2 due to low read counts... what to do?
sampleNormalization(counts.mat, diagnostics = T, returnSizeFactors = T)
```

Clear no normalization is going to fix these samples... thinking now is to try restart from the counts with the concatenated fastq, or else if that doesnt work drop the second sample
I guess there will be no stats etc this way..

```{r}

```


Number of significant hits in each contrast?

Pull out the significant hits in both my and Adrians analysis and generate a heatmap of these

```{r}
g <- ggplot(clean.dt[abs(LFC) > 1 & p.adj < 0.1,.N, by=.(sig,contrast)], aes(x=contrast, y=N, fill=sig)) +
  geom_bar(stat='Identity') +
  scale_fill_manual(values=c('up'=col.pal[2], 'down'=col.pal[1])) +
  ggtitle('Number of significant hits per contrast') +
  ylab(expression(paste('pvalue < 0.005 & abs(LFC)  > 1'))) +
  theme_ipsum_rc(grid = "XY") +
  theme(axis.text.x = element_text(angle=90, size=7),
        panel.border = element_rect(color = "lightgrey",
                                    fill = NA,
                                    size = 1))

BackupAsPDF(g, 'nHitsperContrast.barplot', format='png')
```






This output looks a lot more reasonable... maybe we want to extract the different genes and produce a different kind of plot

Load the enrichment packages
```{r}
# get human DBs ready
gmt.hs.go.bp <- loadGmtFromBioconductor(dbName='org.Hs.eg.db', ontology='BP', keyType='SYMBOL')
gmt.hs.go.cc <- loadGmtFromBioconductor(dbName='org.Hs.eg.db', ontology='CC', keyType='SYMBOL')
gmt.hs.kegg <-  loadKegg(organism='hsa', keyType = 'kegg') # map to entrez ID


# human kegg to symbol and can merge these tables and
hsKeggMap.dt <- clusterProfiler:::bitr(gmt.hs.kegg$gene, fromType='ENTREZID', toType='SYMBOL', OrgDb='org.Hs.eg.db')
gmt.hs.kegg <- merge(x=gmt.hs.kegg, y=hsKeggMap.dt, by.x="gene", by.y="ENTREZID", all.x=T)
gmt.hs.kegg <- gmt.hs.kegg[, .(ont, gene = ifelse(SYMBOL == '', gene, SYMBOL), ont.id)]



test.dt <- data.table(timepoint=c('0','05','10','30'),
           a=c(0,2,4,8),
           b=c(0,4,8,12),
           c=c(0,1,2,1,-1))


ggplot(melt(test.dt, id.vars = 'timepoint'), aes(x=timepoint, y=value, color=variable, group=variable)) +
  geom_point() +
  geom_line() +
  geom_hline(yintercept=0, linetype=2)
```


# looks like te counts for CARD9 are greatly reduced in high CARD9? Is this an older dataset? makes absolutely no sense...
Running w/o non-targeting in Adrians data.. we could try this and also use total normalization?
This would impact the normalization... is this a good thing? Dont think so... one of the samples clearly a lower number of hits, maybe drop from the analysis...
```{r}
runEnrichment <- function(dt, ont, keepCl='MRC5', title, isKEGG=F){
  
  sub.dt <-dt
  
  # pull out bg
  universe <-  unique(sub.dt$id)
  
  # create enrichment groups
  sub.dt[, enrich.grp := interaction(contrast, sig)]
  
  # run GO enrichment on each group seperately
  enrich.dt <- enricherOnGroups(sub.dt[sig != 'not'], 
                              groupColumns = 'enrich.grp', 
                              geneColumn = "id", 
                              term2gene.gmt = ont, 
                              universe = universe)
  
  if (isKEGG) {
    
    return(list(
              enrich=enrich.dt))
    
  } else {
    simp.enrich <- simplifyEnrichBySimilarUniverseMembership(enrichResultsTable = enrich.dt, 
                                                           gmt=ont, 
                                                           groupColumn = 'enrich.grp',
                                                           max_pAdjust = 0.1)
    
    return(list(
              enrich=enrich.dt,
              simpenrich=simp.enrich))
  }
}
```

Run enrichment for each of the different groups
```{r}
hm.bp <- runEnrichment(clean.dt, ont=gmt.hs.go.bp, title='GO Biological Process', isKEGG=F)
hm.cc <- runEnrichment(clean.dt, ont=gmt.hs.go.cc, title='GO Biological Process', isKEGG=F)
hm.kegg <- runEnrichment(clean.dt, ont=gmt.hs.kegg, title='GO KEGG Pathways', isKEGG = T) 

fwrite(hm.bp$enrich, ScriptAndDatedFileName('IBD.totalNorm.GO.BP.enrichment.csv'))
fwrite(hm.bp$simpenrich$simplified, ScriptAndDatedFileName('IBD.totalNorm.GO.BP.enrichment.simplified.csv'))
fwrite(hm.cc$enrich, ScriptAndDatedFileName('IBD.totalNorm.GO.CC.enrichment.csv'))
fwrite(hm.cc$simpenrich$simplified, ScriptAndDatedFileName('IBD.totalNorm.GO.CC.enrichment.simplified.csv'))
fwrite(hm.kegg$enrich, ScriptAndDatedFileName('IBD.totalNorm.KEGG.enrichment.csv'))
```
Look at the enrichment heatmaps for each of the clusters; what are the terms that stand out?

```{r}
plotHeatmap <- function(dt, pThresh=4, nTerms=8){
  
  subDT <- copy(dt) # create cp for modifying
  subDT[, enrich.grp := factor(enrich.grp)]  
  
  ht <- enrichHeatmapBestPerGroup(simplifiedEnrichTable = subDT,
                                  groupColumn = 'enrich.grp', 
                                  cluster_columns=F,
                                  cluster_column_slices=F,
                                  column_split=str_extract(levels(subDT$enrich.grp),'down|up'),
                                  #column_split=list(str_extract(levels(subDT$enrich.grp), '[0-9]{1,2}hpi'),
                                  #                  str_extract(levels(subDT$enrich.grp),'down|up')),
                                  negCols=unique(grep('down', subDT$enrich.grp, value=T)),
                                  topN=nTerms,
                                  row_names_gp = gpar(fontsize = 7), 
                                  column_names_gp= gpar(fontsize = 6), 
                                  upperThreshold = pThresh)
  
  return(ht)
}
```

Generate the enrichment heatmaps

```{r}
ht <- enrichHeatmapBestPerGroup(simplifiedEnrichTable = hm.bp$enrich,
                                  groupColumn = 'enrich.grp', 
                                  cluster_columns=F,
                                  cluster_column_slices=F,
                                #  column_split=str_extract(levels(subDT$enrich.grp),'down|up'),
                                  #column_split=list(str_extract(levels(subDT$enrich.grp), '[0-9]{1,2}hpi'),
                                  #                  str_extract(levels(subDT$enrich.grp),'down|up')),
                                  negCols=unique(grep('down', hm.bp$simpenrich$simplified$enrich.grp, value=T)),
                                  topN=8,
                                  row_names_gp = gpar(fontsize = 7), 
                                  column_names_gp= gpar(fontsize = 6))


ht
hm.bp$enrich[p.adjust < 0.05,]
plotHeatmap(hm.bp$simpenrich$simplified)

BackupAsPDF(plotHeatmap(hm.bp$simpenrich$simplified, keepCl = 'MRC5'),'human.GO.BP.heatmap', dimensions = c(9,6))
BackupAsPDF(plotHeatmap(hm.cc$simpenrich$simplified, keepCl = 'MRC5'),'human.GO.CC.heatmap', dimensions = c(9,6))
BackupAsPDF(plotHeatmap(hm.kegg$enrich, keepCl = 'MRC5'),'human.kegg.heatmap', dimensions = c(9,6))


clean.dt[id %like% 'IRF8',]
```






# why are the CARD9 counts so low? look at Adrians results and see if we can determine what is going on here...
Look at high v library

```{r}
ap.gene.dt <- fread('data/Package_Alicia_Ronald_9-18-2023/mageck_Lib_vs_High_output/mageck_Lib_vs_High.gene_summary.txt')
ap.sgrna.dt <- fread('data/Package_Alicia_Ronald_9-18-2023/mageck_Lib_vs_High_output/mageck_Lib_vs_High.sgrna_summary.txt')


ap.gene.dt[id == 'CARD9']
```

