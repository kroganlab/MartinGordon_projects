---
title: "101624_PWComparisonsDESeq2"
author: "Martin Gordon"
date: "2024-10-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

Reanalyze the data using DESeq2
Takehome: few targets passing thresholds, but could be how I built my model (included all samples; maybe seperate abe8e and bemax experiments?)
Leave for now and proceed with the location/clinvar mapping  of the edit sites
As LRT is similar to ANOVA and we are testing across all levels, it doesnt make sense to use this as a drop-in (only needs to be significant in one comparison to 'pass') So use Wald and filter by LFC
Proceed with WALD test results. FDR @ .25


**Todo**
Try the analysis on a reduced set; just take the control and treatment and maybe compare number of hits to assess if this is useful? Perhaps the full set introduces too much noise/variance in the different guides...
Looking at sample correlations, things are 'pretty' similar across conditions (meaning most things no impact?) So I guess it makes sense to take the full set and use that in variance estimation (bigger N, tigher variance estimates, more sig hits??)
Reducing to just the tested conditions increases variance estimates.. could we use all negative treatments to test this?
```{r}
library(data.table)
library(parallel)
library(ggplot2)
library(magrittr)
library(ComplexHeatmap)
library(viridis)
library(dendextend) # for dendogram modifications
library(DESeq2)
library(patchwork)
library(ggrepel)
library(tidymodels)
library(readxl)

source("../../utils/bp_utils/MSstats_Helper_Functions.R")
source("../../utils/bp_utils/ManageScriptData.R")
source ("../../utils/bp_utils/enrichmentTestFunctions.R")
source ("../../utils/mg_utils/r_utils/IDmapping.R")
source ("../../utils/mg_utils/r_utils/plottingHelperFunctions.R")

source("../../utils/mg_utils/r_utils/CRISPR_Functions.R")

# function to cluster w NA values
clusterWNA <-  function(mat, na.value=0,...){
  
  mat[is.na(mat)] <- na.value
  return(hclust(dist(mat)))
}
```

Read in the raw matrix, the summary tables etc
```{r}
summary.dt <- fread('~/Documents/projects/101224_RBabu_CRISPRe_PIK3CA/101524_MAGECKContrasts_firstPass_data/2024_10_15_sgCount.summary.csv')
count.mat <- fread('~/Documents/projects/101224_RBabu_CRISPRe_PIK3CA/101524_MAGECKContrasts_firstPass_data/2024_10_15_sgNorm.countMat.txt')
genes.anno <- count.mat$Gene

rawMat <- count.mat[,-c('Gene')] %>% 
  as.matrix(rownames='sgRNA')
```

```{r}
sgControls <- read_xlsx('./docs/PIK3CA pathway base editing.xlsx', sheet=1) %>%  
  as.data.table() %>% 
  .[Gene == 'non-targeting', `Sl No`] %>% 
  unique()
```
Need to split the matrix into two groups: bemax and abe8e
```{r}
abe8e.vec <- grep('sgRNA|Gene|abe8', colnames(count.mat), value=T)
bemax.vec <- grep('sgRNA|Gene|bemax', colnames(count.mat), value=T)

abe8e.mat <- count.mat[, ..abe8e.vec]
bemax.mat <- count.mat[, ..bemax.vec]


mat.list <- list('abe8e'= abe8e.mat,
                 'bemax' = bemax.mat)

#convert to matrix
mat.list <- lapply(mat.list, function(x) as.matrix(x[,-c('Gene')], rownames='sgRNA'))
```

Use both normalization methods and merge to original data.table
```{r}
metadata <- summary.dt[, .(sample=paste(editor,treatment,timepoint,rep, sep='_'), group=paste(editor,treatment,timepoint, sep='_'), editor, treatment, timepoint, rep)] %>% 
  as.data.table()

# tidy some of the conditions
metadata[treatment == 'control', treatment := 'DMSO']
metadata[treatment == 'librep', treatment := 'LibraryRep']
metadata[treatment == 'plasmid']
metadata[, treatment := factor(treatment, levels=c('LibraryRep', 'DMSO', 'Paxalisib', 'Alpelisib'))]
metadata[, timepoint := factor(timepoint, levels=c('0','7', '22'))]
  
# make a new condition group and lets use that for our comparisons
metadata[, condition := factor(paste0(treatment, '_',timepoint))]
metadata[, condition := relevel(condition, ref='LibraryRep_0')]


# tidy the plasmid comparison group
metadata[group == 'plasmid_librep_0', c('editor', 'treatment', 'timepoint') := .('na', 'na', 0)]


abe8e.meta <- metadata[grepl('abe8|plasmid', sample),] %>% 
    as.data.frame(row.names = .$sample)
bemax.meta <- metadata[grepl('bemax|plasmid', sample),] %>% 
  as.data.frame(row.names = .$sample)


meta.list <- list('abe8e'= abe8e.meta,
                 'bemax' = bemax.meta)

meta.list[[1]]$condition %>%  unique()
meta.list[[1]]$treatment %>%  unique()
```


```{r}
# reorder the matrix columns
mat.list <- lapply(names(mat.list), function(i){
  
  mat.list[[i]] <- mat.list[[i]][, rownames(meta.list[[i]])]
  return(mat.list[[i]])
  
})
names(mat.list) <- c('abe8e', 'bemax')

# all true
colnames(mat.list[[1]]) == rownames(meta.list[[1]])
colnames(mat.list[[2]]) == rownames(meta.list[[2]])

mat.list
meta.list
```


run DESeq2 on the seperated datasets (set size factors to 1 to avoid re-normalizing)

```{r}
# first run DESeq2 with the full set on the two editors seperately
deseq.list <-lapply(names(mat.list), function(x,y,i){
  
  dds <- DESeqDataSetFromMatrix(countData = round(x[[i]]),
                                colData = y[[i]],
                                design = ~condition)
  
  dds <- estimateSizeFactors(dds)
  print(sizeFactors(dds))
  # run DESeq2 w/o normalization
  # replace the size factors
  sizeFactors(dds) <- replace(sizeFactors(dds), 1:length(sizeFactors(dds)), 1)
  return(dds)
},x=mat.list, y=meta.list)

names(deseq.list) <-  names(mat.list)
```

Lets filter out the sets with low counts; want at least 10 reads in 75% of the data

```{r}
deseq.list <- lapply(names(deseq.list), function(x,i){
    
  keep <- rowSums(counts(x[[i]]) >= 10) >= 11
  dds <-  x[[i]][keep,]
  
  message('Retaining ', nrow(dds), ' guides ', 'from ', nrow(counts(x[[i]])))
  return(dds)
  
},x=deseq.list)

names(deseq.list) <-  names(mat.list)
```

Save the two deseq objects for now

```{r}
lapply(names(deseq.list), function(x,i){
  #x[[i]]
  #saveRDS(x[[i]], file=paste0("/Users/martingordon/Documents/projects/101224_RBabu_CRISPRe_PIK3CA/161024_PWComparisons_DESeq2_data/", i, '.dds.obj'))
},x=deseq.list)
```
Now run deseq2 on the two groups
```{r}
# here we are basically testing if the addition of a 'condition' term produces a model with a better 'fit' than the basic model
lrt.de.list <- lapply(deseq.list, function(x){
  
  dds <- DESeq(x, test='LRT', reduced=~1)
  
  contrasts.oi<- grep('Intercept', resultsNames(dds), invert=T, value = T)
  print(contrasts.oi)
  
  all.res <- lapply(contrasts.oi, function(n){
    
    res <- results(dds, name=n) %>% 
      as.data.table(., keep.rownames=T) %>% 
      .[, contrast := n]
  }) %>% rbindlist()
  
  
  return(all.res)
})

lrt.de.dt <- rbindlist(lrt.de.list, idcol='editor')


de.list  <- lapply(deseq.list, function(x){
  
  dds <- DESeq(x)
  
  contrasts.oi<- grep('Intercept', resultsNames(dds), invert=T, value = T)
  
  all.res <- lapply(contrasts.oi, function(n){
    
    res <- results(dds, name=n) %>% 
      as.data.table(., keep.rownames=T) %>% 
      .[, contrast := n]
  }) %>% rbindlist()
})


de.dt <- rbindlist(de.list, idcol='editor')

setnames(de.dt, old='rn', new='sgRNA')
setnames(lrt.de.dt, old='rn', new='sgRNA')


de.list <- list('wald'=de.dt,
                'LRT'= lrt.de.dt)
```
 # set our sig threshold
 # start with FDR < 0.1 for now and LFC > 1 
```{r}
lapply(de.list, function(x){

  print(x[padj < 0.1 & abs(log2FoldChange) > 1, .N, by=.(editor, contrast)])
  #print(x[pvalue < 0.005 & abs(log2FoldChange) > 1, .N, by=.(editor, contrast)])
  
  x[, sig := 'not']
  x[abs(log2FoldChange) > 1 & padj < 0.1, sig := ifelse(log2FoldChange > 0 ,'up', 'down')]
})


# need to add gene info to the list 
gene.info <- read_xlsx('./docs/PIK3CA pathway base editing.xlsx', sheet=1) %>%  
  as.data.table() %>% 
  .[,.('sgRNA'=`Sl No`,'gene'=Gene)]

gene.info[gene %like% 'sgINTERGENIC', gene := 'Intergenic']
gene.info[, gene := toupper(gene)]

# write out the results to file. For now lets stick with the LFC vs control group
lapply(names(de.list), function(x, i){

  dt <- merge(x[[i]], gene.info, by='sgRNA', all.x=T)
  dt[, contrast := sub('condition_', '',contrast)]
  fwrite(dt, ScriptAndDatedFileName(paste0(i,'deseq2.vsT0.csv')))
  
},x=de.list)

help(DESeq2::results)
```
Lets repeat the same analysis as earlier; lets count the number of sig hits from each

```{r}
de.dt <- fread('~/Documents/projects/101224_RBabu_CRISPRe_PIK3CA/161024_PWComparisons_DESeq2_data/2024_10_30_walddeseq2.vsT0.csv')
```
Create a couple more factor variables 

```{r}
de.dt[, sig := 'not']
de.dt[abs(log2FoldChange) >= 1 & pvalue < 0.005, sig := ifelse(log2FoldChange > 0, 'up', 'down')]
de.dt[, numeratorTimepoint := factor(gsub('_', '', str_extract('_[027]+_', contrast)), levels=c('0','7','22'))]
de.dt[, direction := ifelse(log2FoldChange > 0, 'up', 'down')]
```

Looks like we have a lot of noise in the bemax set
Weirdly, again most of the things moving are upregulated..

```{r}
# breakdown by contrast
g <- ggplot(de.dt[,.N, by=.(sig, contrast, editor, numeratorTimepoint)][sig != 'not',], aes(x=reorder(contrast, as.numeric(numeratorTimepoint)), y=N, fill=sig)) +
  geom_bar(stat='Identity') +
  facet_wrap(~editor, scales='free') +
  ggtitle('Significant sgRNA (Log2FC >= 1 & pval < 0.005)') +
  scale_fill_manual(values=c('up'='#990033', 'down'='#336699')) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=90, size=7))
g
BackupAsPDF(g, 'NsigHits.barchart')


# look at direction of movement
# seems equal distribution of things moving, but most of the sig resulta are the upregulated...
#definitely need better filtering of guides.. leave as is for now...
g <- ggplot(de.dt[abs(log2FoldChange) > 1, .N, by=.(direction, contrast, editor, numeratorTimepoint)], aes(x=reorder(contrast, as.numeric(numeratorTimepoint)), y=N, fill=direction)) +
  geom_bar(stat='Identity') +
  facet_wrap(~editor, scales='free') +
  ggtitle('Significant sgRNA (Log2FC >= 1 & FDR < 0.1)') +
  scale_fill_manual(values=c('up'='#990033', 'down'='#336699')) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=90, size=7))
g
```
breakdown by gene and contrast 
```{r}
# breakdown by contrast and gene
g <- ggplot(de.dt[,.N, by=.(sig, gene, editor, numeratorTimepoint, contrast)][sig != 'not',], aes(x=editor, y=N, fill=sig)) +
  geom_bar(stat='Identity') +
  facet_grid(gene~contrast, scales='free_y') +
  ggtitle('Significant sgRNA (Log2FC >= 1 & p.adjust < 0.1)') +
  scale_fill_manual(values=c('up'='#990033', 'down'='#336699')) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=90),
        strip.text.x = element_text(size=7))
g
BackupAsPDF(g, 'sgRNA.sigHits.breakdownbyGeneandContrast', dimensions=c(11,14))
```
I would like a quick plot of the sig hits in each contrast
```{r}
de.dt[, group := paste(editor, contrast)]

lapply(unique(de.dt$group), function(x){
  
  subdt <- de.dt[group == x,]
  
  plot.title <- subdt$contrast
  
  g <- ggplot(subdt, aes(x=log2FoldChange, y=-log10(pvalue), color=sig, label=sgRNA)) +
  geom_point() +
  geom_vline(xintercept = c(-1,1), linetype=2, alpha=0.4) +
  geom_hline(yintercept = -log10(0.005), linetype=2, alpha=0.4) +
  geom_text_repel(data=subdt[sig !='not'], show.legend = F, size=2, max.overlaps = 20) +
  facet_wrap(~gene, ncol=3, scales='free_y') +
  ggtitle(x) +
  ylab('-log10 p-value') +
  xlab('Log Fold Change') +
  scale_color_manual(values=c('up'='#990033', 'down'='#336699', 'not'='grey')) +
  #scale_color_viridis(option='D') +
  theme_classic() 
  
  g
  BackupAsPDF(g, paste0('volcanoplots_individual/gene/',x ,'.volcanoplots'), dimensions=c(11,8))
})
```

What would be a nice plot is a heatmap of the sig moving guides with the following two annotations i) gene and ii) is_domain binary

For this, the best approach would be to build a annotation file for each of the guides, including window in gene, mutation severity, and if this overlaps with a known domain

Lets first annotate with gene info; for now we need to find the sites where the guides align
```{r}
genes.dt <- data.table(transcriptID=c('ENST00000371953', 'ENST00000361445', 'ENST00000649815', 'ENST00000263967'),
                       gene=c('PTEN', 'MTOR', 'AKT1', 'PIK3CA'))

# first load the gene information 
anno.dt <- fetchGeneFeatures(gene_symbol = genes.dt$gene, tID=genes.dt$transcriptID)
anno.dt[, fetchPeptideSequencefromEnsemblTranscriptID(tID=ensembl_transcript_id), by=.I]

clinvar.dt <- getClinvarDT(path='/Users/martingordon/Documents/projects/071724_BRabu_CRISPRbe_LibraryDesign/data/GRCh38.snp_clinvar.txt',ref='GRCh38',  genesOI = c("PTEN" ,"MTOR","AKT1","PIK3CA"), variantOI = "single nucleotide variant")
```
want to get domain info from this dataset; can we get protein domain info
```{r}
domains.dt <- fetchInterProtDomains(gene_symbol=anno.dt$external_gene_name, tID=anno.dt$ensembl_transcript_id, keep='largest')
domains.dt <- merge(anno.dt, domains.dt, by=c('ensembl_transcript_id', 'external_gene_name'))
domains.dt[, domainSequence := substr(peptideSequence, interpro_start, interpro_end)]
```
Next thing we need to do is get the guide position(s); easiest approach is to merge the sgRNA dt with the clinvar
```{r}
# position here is for first base in guide given relative to pos strand on GRcH38
sgrna.dt <- read_xlsx('/Users/martingordon/Documents/projects/101224_RBabu_CRISPRe_PIK3CA/docs/PIK3CA pathway base editing.xlsx', sheet=1) %>% 
  as.data.table()

# tidy names 
sgrna.dt[Gene %like% 'sgINTERGENIC', Gene := 'intergenic']
sgrna.dt[, Gene := toupper(Gene)]

#whats clear here to me is these are using different annotations; the regions dont seem to match. If we align starting positions we can see these have different annotations
anno.dt[external_gene_name == 'PTEN',]
sgrna.dt[Gene == 'PTEN',][,.(Gene,Position)][order(Position)]
clinvar.dt[GeneSymbol == 'PTEN',.(Name, GeneSymbol,Start)][order(Start)]

# only two positions overlap... clear we are using different referecnes...
clinvar.dt[Start %in% sgrna.dt$Position, .N, by=GeneSymbol]
```
Want this tool to work with essentially two files: a file of sgRNA sequences and the clinvarDB
clinvarDB reports variants with an offset of 1
For single nucleotide variants not in repeat regions, the location based on VCF or HGVS matches on nucleotide position
variant summary file is consistent with HGVS nomenclature

```{r}

# what about the controls, do we want to align them? No strand info, but could just align to both strands and see how it goes
align.in.dt <- merge(x=sgrna.dt[,.(`Sl No`,Gene, `Guide Strand`, Position, Guide)], y=anno.dt, by.x='Gene', by.y='external_gene_name', all.x=T)

getSeqReverseComplement <- function(sequence){
  require(Biostrings)
  if (grepl('U', sequence)){
    
    seq.obj <- RNAStringSet(sequence)
    return(as.character(reverseComplement(seq.obj)))
    
  } else {
    
    seq.obj <- DNAStringSet(sequence)
    return(as.character(reverseComplement(seq.obj)))
  }
}

# need our guide seq to be on + strand for alignment as all the ref is + strand
# question: guide strand: does this mean same strand of the gene or is it relative to the reference strand? assuming it means strand of gene
# after alignment, break down align stats per criteria can spot issues based on these criteria
align.in.dt[, SeqToAlign := ifelse(`Guide Strand` == 1 & strand == 1, Guide, # if guide is on pos strand and so is gene, take the sequence
                                    ifelse(`Guide Strand` == 1 & strand == -1, getSeqReverseComplement(Guide), # need pos strand seq for search
                                           ifelse(`Guide Strand` == -1 & strand == -1, Guide, getSeqReverseComplement(Guide))) ), by=.I] 


# simplier; if -1 its on -ve strand so map to +
align.in.dt[, SeqToAlign2 := ifelse(`Guide Strand` == 1, Guide, getSeqReverseComplement(Guide)),by=.I]
```
Run the alignment to reference genome, map the guides to the gene annotation data
```{r}
# run this as part of the function
getGuideStrand <- function(geneStrand, guideStrand){
  
  geneStrand <- as.character(geneStrand); guideStrand <- as.character(guideStrand)
  # easier option would be to convert both symbols to be the same and could do a simple logical ==/!= but fine for now
  return(ifelse(geneStrand == '1' & guideStrand == '+', 'sense',
                        ifelse(geneStrand == '-1' & guideStrand == '-', 'sense', 'antisense')))
}

# so this is all our guide alignments targeting genes (could we also do the non-targeting?)
align.out.dt <- alignToReference(seqIn = align.in.dt$Guide, ref='GRCH38', chrToSearch = 'all', strand='both', nCores = 2)

# want to get N off-target hits
nHits.dt <- align.out.dt[,.(nHits = .N), by=Guide]

# assuming here all we have is the guide info; we may also have the gene/chr it belongs to, so we can filter by either i)

# smaller keyed index dt with wider intervals; index start and end of gene position
setkey(anno.dt, start_position, end_position)
all(key(anno.dt) == c("start_position","end_position"))


# map to gene annotation if guide and gene intervals overlap (guides must be within gene range)
# is this chr filtering stringent enough? will catch cases where the genomic regions overlap between guide align and gene info but chr doesnt, but may fail with many guides.. maybe test for 
# drop rows with no overlap (just filter to genes)
# we want to drop guides that dont match and also
# mayeb run on align.out.dt to avoid creating a new copy....
guides.dt <- foverlaps(x=align.out.dt, y=anno.dt, by.x=c('pos_align_start', 'pos_align_end'), nomatch=0, type='within') %>% 
  .[chromosome_name == i.chromosome_name, .(guide=Guide, chr=as.character(chromosome_name), gene=external_gene_name, strand, ensembl_tID=ensembl_transcript_id, guide_strand=getGuideStrand(geneStrand = strand, guideStrand = align_strand), pos_align_start, pos_align_end, gene_start=start_position, gene_end=end_position, transcript_start, transcript_end)]

if (length(duplicated(guides.dt$Guide)) != 0)
  print('Following guides perfectly aligned to more than one gene\n', paste0(guides.dt$Guide[duplicated(guides.dt$Guide)], collapse=','))
  print('Consider removing from further analyisis')
```

```{r}
guides.dt[order(pos_align_start)][, .(gene, strand, gene_start, gene_end, transcript_start, transcript_end)] %>% 
  unique()
```

```{r}
# get the edits
guides.dt[, abe8e :=  getCodingSequenceEdit(guide, guideStrand = guide_strand, editor='abe8e', window_start = 4, window_end=8), by=.I]
guides.dt[, bemax :=  getCodingSequenceEdit(guide, guideStrand = guide_strand, editor='bemax', window_start = 4, window_end=8), by=.I]

guides.dt


sgrna.dt
# melt the datatable to long format
guides.dt <- melt(guides.dt, measure.vars = c("abe8e","bemax"))
setnames(guides.dt, old=c('variable', 'value'), new=c('editor', 'editSequence'))
```

All we need for the merging is the clinvarDt and the sgRNA.dt
We know now with our alignments that the Positon in sgRNA.dt is same as first base aligned to the pos strand on GRCh38
Next, we need to find the positions of edit windows on sgRNA.dt, create an edited sequence based on possible edits, find the i)index and ii)base and see if there is a corresponding match in clinvar db 

# given guide sequence, an edit window and an editor find the potential edits and their locations
# will use this to match to clinvarDB

# I think we want to find our edits in the specified window
```{r}
#' Idea at the minute is that the guide is in 5-3' orientation
#' more sanity checks to 
getCodingSequenceEdit <- function(Seq, window_start, window_end, guideStrand=NULL, editor=NULL){

  if (as.character(guideStrand) %in% c('-1','1')){
    guideStrand <- ifelse(guideStrand == '-1', 'antisense', 'sense')
  }
  
  if(!toupper(editor) %in% c('BEMAX','ABE8E'))
    stop('Must specify editor (either ABE8E or BEMAX)')
  
  if(!is.numeric(window_start) | !is.numeric(window_end))
     stop('window start and window end must be numeric')
  
  if(nchar(Seq) < (window_end - window_start) | nchar(Seq) < window_start | nchar(Seq) < window_end)
    stop('check edit window range')
  
  editSeq <- Seq
  # edits applied on the 'sense' stand. Easier to follow window...            
  #if (as.character(guideStrand)== 'antisense'){
  #  editSeq <- as.character(Biostrings::reverseComplement(Biostrings::DNAStringSet(editSeq)))
  #}
  
  # handling strandedness of guide; modify the sequence 'as is'
  #editSeq <- ifelse(toupper(editor) == 'BEMAX' & guideStrand == 'sense', paste0(substr(editSeq, 1, window_start-1), gsub('C', 'T', substr(editSeq, window_start, window_end), fixed=T), substr(editSeq, window_end+1,nchar(editSeq))),
  #                  ifelse(toupper(editor) == 'BEMAX' & guideStrand == 'antisense', paste0(substr(editSeq, 1, window_start-1), gsub('G', 'A', substr(editSeq, window_start, window_end), fixed=T), substr(editSeq, window_end+1,nchar(editSeq))),
  #                         ifelse(toupper(editor) == 'ABE8E' & guideStrand == 'sense', paste0(substr(editSeq, 1, window_start-1), gsub('A', 'G', substr(editSeq, window_start, window_end), fixed=T), substr(editSeq, window_end+1,nchar(editSeq))),
  #                                paste0(substr(editSeq, 1, window_start-1), gsub('T', 'C', substr(editSeq, window_start, window_end), fixed=T), substr(editSeq, window_end+1,nchar(editSeq))) )))
  
  editSeq <- ifelse(toupper(editor) == 'BEMAX', paste0(substr(editSeq, 1, window_start-1), gsub('C', 'T', substr(editSeq, window_start, window_end), fixed=T), substr(editSeq, window_end+1,nchar(editSeq))),
                                                  paste0(substr(editSeq, 1, window_start-1), gsub('A', 'G', substr(editSeq, window_start, window_end), fixed=T), substr(editSeq, window_end+1,nchar(editSeq))))
    
    
  if (as.character(guideStrand)== 'antisense'){
    editSeq <- as.character(Biostrings::reverseComplement(Biostrings::DNAStringSet(editSeq)))
  }

  return(editSeq)
}
```
# get the edited sequence for both editor types. Convert the data.table to long format
```{r}
guides.dt.backup <- copy(guides.dt)

# get the edits
guides.dt[, abe8e :=  getCodingSequenceEdit(guide, guideStrand = guide_strand, editor='abe8e', window_start = 4, window_end=8), by=.I]
guides.dt[, bemax :=  getCodingSequenceEdit(guide, guideStrand = guide_strand, editor='bemax', window_start = 4, window_end=8), by=.I]

sgrna.dt[, abe8e.edit := getCodingSequenceEdit(Guide, guideStrand = `Guide Strand`, editor='abe8e', window_start = 4, window_end=8), by=.I]
sgrna.dt[, bemax.edit := getCodingSequenceEdit(Guide, guideStrand = `Guide Strand`, editor='bemax', window_start = 4, window_end=8), by=.I]


sgrna.dt[is.na(`Guide Strand`),]
# melt the datatable to long format
guides.dt <- melt(guides.dt, measure.vars = c("abe8e","bemax"))
setnames(guides.dt, old=c('variable', 'value'), new=c('editor', 'editCodingSequence'))
```

Sanity check; compare our bemax guides to the set produced by sgrna

```{r}
#1533 empty guides here
guides.dt[editor == 'bemax' & guide %in% check.guides & base_editor == '', unique(guide)] %>% length()

bemax.empty <- guides.dt[editor == 'bemax' & guide %in% check.guides & base_editor == '', unique(guide)] 

# looks like Ronald set the edit window as 1-8 for his guides....
#sgrna.dt[Guide %in% bemax.empty, unique(edit_index)] %>%  strsplit(.,';') %>%  unlist() %>%  unique() %>% as.numeric() %>%  sort()


sgrna.dt
```
**Note**
For the aa annotation, we need to find the transcript start site on the gene and find the exon boudaries, I see this as a datatable (GRANGES object??) with: i) gene index, nucleotide base, type (gene < transcript < cds), aa just take the bases 
```{r}
unique(check.guides) %>%  length()
```


Now want to get the edit indexes (want these on the coding strand to map to the clinvar variants)
```{r}
# new function
findEditIndex <- function(Seq, editSeq, guideStrand=NULL, editScores=NULL){
  
  if(nchar(Seq) != nchar(editSeq))
    stop('reference and edit sequences length mismatch. Aborting..')
  
  if (as.character(guideStrand) %in% c('-1','1')){
    guideStrand <- ifelse(guideStrand == '-1', 'antisense', 'sense')
  }
  
  if (as.character(guideStrand)== 'antisense'){
    Seq <- as.character(Biostrings::reverseComplement(Biostrings::DNAStringSet(Seq)))
  }

  refSet <- strsplit(Seq,'')[[1]]; editSet <- strsplit(editSeq,'')[[1]]
  # get mismatch indices
  edit.idx <- which(refSet != editSet)
  editbase <- unique(editSet[edit.idx])
  
  # sanity check compare to the number of edit socres we detect, if off abort
  if (!is.null(editScores)){
    
    if (length(edit.idx) != length(strsplit(editScores, ', ')[[1]]) )
      stop('Found different number of edits vs reported in the sgrna input file\n Offending guide: ', Seq)
  }
  
  if (as.character(guideStrand) == 'sense'){
    
    return(list(index=paste(edit.idx,collapse=';'),
                editor=paste(ifelse(editbase %in% c('T'), 'bemax', 'abe8e'), collapse=';'),
                ref=paste(refSet[edit.idx], collapse=';'),
                alt=paste(editSet[edit.idx], collapse=';')))
    
  } else if  (as.character(guideStrand) == 'antisense'){
    
    return(list(index=paste(edit.idx,collapse=';'),
                editor=paste(ifelse(editbase %in% c('A'), 'bemax', 'abe8e'), collapse=';'),
                ref=paste(refSet[edit.idx], collapse=';'),
                alt=paste(editSet[edit.idx], collapse=';')))
  }
}


guides.dt[editor == 'abe8e',][base_editor != '',]
```

Now; identify the edit sites and bases
Looks like out of our set of guides, something like 1/4 of these produce no edits in one of the two sets

Ronalds data set is not annotated correctly (mostly bemax edits, not limited to window), I dont know if my code is performing performing the alignments correctly..
Options, stay writing own or look at others code. 


What are the edits I am missing at the moment.. are they aligned to one strand or one gene or one guide strand?? investigate
```{r}
guides.dt[, c('edit_index', 'base_editor', 'ref_base', 'alt_base') := findEditIndex(Seq=guide, editSeq=editCodingSequence, guideStrand = guide_strand), by=.I]
guides.dt[,.(base_editor, strand, guide_strand, ref_base, alt_base, edit_index)] %>% unique()

# check if accurate
guides.dt[, c('ref_unique', 'alt_unique') := lapply(.SD, function(x){ unique(strsplit(x,';')[[1]]) }), .SDcols = c("ref_base", "alt_base"), by=.I]

# looks like there could be many more sites with no edits, but most restricted to one editor or antoher
# the edits in relation to strand look good, but need to check all these empty edit strings..
guides.dt[,.N, by=.(strand, guide_strand, base_editor, editor, ref_unique, alt_unique)][base_editor != '',] %>% unique()


# one quarter are empty edits using this method... looks totally wrong...c
check.guides <- guides.dt[base_editor == '', unique(guide)]

guides.dt[guide %in% check.guides,][,.(guide, strand, guide_strand, editor)][guide == 'CAAAAATGTGATGGTTCAGT',]

guides.dt[guide %in% 'CAAAAATGTGATGGTTCAGT',]
sgrna.dt[Guide == 'CAAAAATGTGATGGTTCAGT',]
# find any guides that are not edited by both editors
# here you would ant to check for n editors, if only 1should be 0
noEditGuides <- guides.dt[(base_editor) == '', .N, by=guide][N > 1, guide]

message(length(noEditGuides),' guides introduced no edits in the specified targeting window\n', paste(noEditGuides, collapse=';'))
message('We recommend dropping this guide set from furhter analysis')


sgrna.dt[editor == 'bemax' & Guide %in% check.guides, unique(edit_index)]
sgrna.dt[grepl('abe8e',editor) & grepl('bemax', editor),]
sgrna.dt[, .N, by=editor][order(N)]
sgrna.dt[, .(`Guide Strand`,Gene, ref_base, alt_base, editor)] %>%  unique()

guides.dt[guide %in% c('ATGCCTCCACGACCATCATC', 'CATTGTTCTGATTCTTTGCA', 'GTTCACCTGATGATGGTCGT', 'CACCTGATGATGGTCGTGGA'),.(guide, editCodingSequence, ref_base, alt_base,edit_index)][order(guide)]
```

The ones we detected fall outside the edit window we are investigating; why are the edits included in the set? off-site edits?

Now match the edits to the clinvar DT
First, break apart the clinvar annotation to position, ref abse and edit base

Examples of HGVS nomenclature

Types of substitution available 
c.76A>C denotes that at nucleotide 76 an A is changed to a C
c.-14G>C denotes a G to C substitution 14 nucleotides 5' of the ATG translation initiation codon
c.88+1G>T denotes the G to T substitution at nucleotide +1 of an intron (in the coding DNA positioned between nucleotides 88 and 89)
c.89-2A>C denotes the A to C substitution at nucleotide -2 of an intron (in the coding DNA positioned between nucleotides 88 and 89)
c.*46T>A denotes a T to A substitution 46 nucleotides 3' of the translation termination codon
the description c.76_77delinsTT is preferred over c.[76A>T; 77G>T]

```{r}
# first, we need to split out the edit position 
message('Tidying with clinvar database..')

# these look like non-coding mutations
# only looking at substitutions as specifying '>'
# something like: 	NC_000010.11:g.87863548G>T

clinvar.edit.dt <- clinvar.dt[, .(chr=Chromosome, gene=GeneSymbol, hgvs=Name,
                              #    reference=str_extract(clinvar.dt$Name, '[A-Z0-9//.//_]+(?=[(:])'),  #using this as may want to filter clinvar downstream
                              #    edit=str_extract(clinvar.dt$Name, '(?<=:[gc].)[0-9+-//*]+[ACGT]>[ACGT]'), origin=Origin,
                                  clinicalSignificance=ClinicalSignificance, position=Start, ref=ReferenceAlleleVCF, alt=AlternateAlleleVCF)]

# I think we want to map positions and ref and alt alleles
clinvar.edit.dt[position == '179234297',]
```
extend rows of the guides DT with mutliple modifications, and then change the position where the mutation is 


*Todo*
Change the pos_align_start/end to ifesle(guide_strand == 'antisense', pos_align_end, pos_align_start)
This way, just need to use one of these points
```{r}
message('matching clinvar edits with guides')
message('dropping guides with no detected edits in edit window')

# works perfeclty to split up the rows, but drops rows with no found; want to keep all rows with no edits found too
guides.expanded <- guides.dt[, lapply(.SD, function(x) unlist(tstrsplit(x, ";"))), .SDcols = c("edit_index", "ref_base", "alt_base"), by = .(guide, chr, gene, strand, ensembl_tID, guide_strand, pos_align_start, pos_align_end, editor, editCodingSequence)]

#enable earlier in the pipeline
#guides.expanded[, chr := as.character(chr)]

# matching sites needs work; easy on + strand sense guide, others more 'hacky'; 
# see if the antisense strand is 
guides.expanded[, edit_position := ifelse(strand == '1' & guide_strand == 'sense', pos_align_start + as.numeric(edit_index)-1, 
                                          ifelse(strand == '1' & guide_strand == 'antisense', pos_align_end - (nchar(guide) - as.numeric(edit_index)), 
                                                 ifelse(strand == '-1' & guide_strand == 'sense',  pos_align_end, pos_align_end

                                          
                                          )))]         #pos_align_start + nchar(guide) + (-as.numeric(edit_index)-1), pos_align_start)) ]

# matching on ref and alt as this is on the positive strand
message('merging guides with clinvar annotations...')
merged.dt <- merge(x=guides.expanded, y=clinvar.edit.dt, by.x=c('chr', 'gene', 'ref_base', 'alt_base','edit_position'), by.y=c('chr', 'gene','ref', 'alt', 'position'), all.x=T)

message('Collapsing guides')
collapsed.dt <- merged.dt[, lapply(.SD, function(x) paste0(x, collapse=';')), .SDcols = c('edit_index', 'ref_base', 'alt_base', 'edit_position', 'hgvs', 'clinicalSignificance'), by=.(chr, gene, ensembl_tID, strand, guide, guide_strand, editor)]

merged.dt[guide == 'CTGGTAACTGGAGGCCCAGA',]
# lets just force the ref base to match,not alt and see how our merge looks
#merged.dt <- merge(x=guides.expanded, y=clinvar.edit.dt, by.x=c('chr', 'gene', 'ref_base','edit_position'), by.y=c('chr', 'gene','ref', 'position'))

merged.dt[gene == 'PIK3CA' & guide_strand == 'antisense',]


# all of these should be C->T edits for bemax
# A -> G edits for abe8e
merged.dt[gene == 'PIK3CA' & guide_strand == 'sense' & editor == 'bemax',]
merged.dt[gene == 'PIK3CA' & guide_strand == 'sense' & editor == 'bemax',]
merged.dt[gene == 'PIK3CA' & guide_strand == 'antisense' & editor == 'bemax',]
merged.dt[gene == 'PIK3CA' & guide_strand == 'antisense' & editor == 'bemax',]

```
Looks like this merge may be performed incorrectly; read in the guides.dt table from base editor script and compare overlaps

```{r}
be.editor.guides <- list(abe8e = fread('./docs/110124.Abe8e_24-11-04-10-41-59/clinvar_annotations_110124.Abe8e.txt', sep='\t', fill=T),
                         bemax = fread('./docs/110124.BEmax_24-11-04-10-42-43/clinvar_annotations_110124.BEmax.txt', sep='\t', fill=T)
                         ) %>% rbindlist(idcol='editor')


be.editor.final <- list(abe8e = fread('./docs/110124.Abe8e_24-11-04-10-41-59/sgrna_designs_110124.Abe8e.txt', sep='\t', fill=T),
                         bemax = fread('./docs/110124.BEmax_24-11-04-10-42-43/sgrna_designs_110124.BEmax.txt', sep='\t', fill=T)
                         ) %>% rbindlist(idcol='editor')
```
How many of our guides are in the be editor output?  Turns out these are very different, but maybe we can try use the overlaping set to validate


**Note on the be output**
No issues with guides; both sets looks good
gene + and sense guide looks good

BE tool output includes mutations *not present in clinvar??** where is it getting these annotations?

Step back to our guides.dt table (before clinvar matching and merging) and compare
It looks like their guide alignment considers combinatorics... is this related to codon structure? makes sense with genetic code redundancy..
Maybe we want to consider all possible combinations.. come back to this after meeting
```{r}
overlapping.guides <- intersect(be.editor.final$`sgRNA sequence`, collapsed.dt$guide)
be.editor.final[`sgRNA sequence` %in% overlapping.guides & grepl('Pathogenic', `Clinical significance`),]


guides.dt[ guide_strand == 'antisense' & gene == 'PIK3CA' & guide %in% overlapping.guides,][edit_index != '',.N, by=guide][order(-N)]

# take a look at all examples of guides (gene and guide strand combos) to see what match

# gene + and sense guide; bemax
# edits match, align position matches (1st base in guide) and edit positions match
#guides.dt[guide == 'ATGCCTCCACGACCATCATC' & editor == 'bemax',]
be.editor.final[`sgRNA sequence` == 'ATGCCTCCACGACCATCATC' & editor == 'bemax',]
collapsed.dt[guide == 'ATGCCTCCACGACCATCATC',] #edit position 179198829;179198830;179198832;179198833


# gene+ and sense guide; abe8e
# edits match, align position matches (1st base in guide) and edit positions match
#guides.dt[guide == 'AGCAGGAGAAAGATTTTCTA' & editor == 'abe8e',]
be.editor.final[`sgRNA sequence` == 'AGCAGGAGAAAGATTTTCTA' & editor == 'abe8e',]
collapsed.dt[guide == 'AGCAGGAGAAAGATTTTCTA',] 

# gene+ and antisense guide; bemax
# here first position is pos_end_align in our data as the guide is on the antisense
guides.dt[guide == 'CTAACGATCTCTTTGATGAT' & editor == 'abe8e',]
be.editor.final[`sgRNA sequence` == 'CTAACGATCTCTTTGATGAT' & editor == 'abe8e',]
collapsed.dt[guide == 'CTAACGATCTCTTTGATGAT' & editor == 'abe8e',] 


collapsed.dt[hgvs != '' & editor == 'abe8e' & guide_strand == 'antisense' & strand == '1' & guide %in% overlapping.guides,][,.N, by=guide][order(-N)]

guides.expanded[edit_position %in% c(179198826, 179198827, 179198829)]
be.editor.final[`sgRNA sequence` == 'ACGATCTCTTTGATGATGGC' & editor == 'bemax',]
```
One thing to do; for annotating edits, we can get the reverse complement, then implement the edits, then 

```{r}
# so, even though these 
87864495 - 6 -1

clinvar.edit.dt[position %between% c(87864490,87864497)][order(position)]
```


```{r}
setdiff(guides.dt$guide,be.editor.final$`sgRNA sequence`) %>% length() # over 1k in ours not in be set..
setdiff(be.editor.final$`sgRNA sequence`, guides.dt$guide)  %>% length() # 934 in be editor not in ours

#2047 guides different between the two sets.. not great
union(setdiff(guides.dt$guide,be.editor.final$`sgRNA sequence`), setdiff(be.editor.final$`sgRNA sequence`, guides.dt$guide)) %>%  unique() %>% length()

setdiff(unique(guides.dt$guide), unique(be.editor.final$`sgRNA sequence`)) %>% length()
fsetdiff(x=data.table(unique(be.editor.final$`sgRNA sequence`)), y=data.table(unique(guides.dt$guide)), all=T)
fsetdiff(x=data.table(unique(guides.dt$guide)), y=data.table(unique(be.editor.final$`sgRNA sequence`)), all=T)
help(setdiff)
```


One of our approaches is completely wrong here...
```{r}
merged.dt[guide == 'CTGCCAGTGCTATATTGGCT',]
be.editor.final[`sgRNA sequence` == 'CTATATTGGCTGGTGAGTGG',]

be.editor.final[,.N,by=.(`sgRNA sequence`)]
```



```{r}
test.dt <- copy(guides.dt)


test.dt[, c('abe8e_edit_index', 'abe8e_editor', 'abe8e_ref_base', 'abe8e_alt_base') := findEditIndex(Seq=guide, editSeq=abe8e_codingSeq, guideStrand = guide_strand), by=.I]
test.dt[, c('bemax_edit_index', 'bemax_editor', 'bemax_ref_base', 'bemax_alt_base') := findEditIndex(Seq=guide, editSeq=bemax_codingSeq, guideStrand = guide_strand), by=.I]
test.dt[is.na(bemax_ref_base) & is.na(abe8e_ref_base),]
findEditIndex(Seq = test.dt$guide, editSeq = test.dt$abe8e_codingSeq, guideStrand = test.dt$guide_strand)

noEditGuides <- test.dt[is.na(bemax_editor) & is.na(abe8e_editor), unique(guide)]

# how do they look in the other data; all found; run the algorithm again to see if any of these edits are inside the edit window
sgrna.dt[toupper(Guide) %in% noEditGuides,]
colnames(sgrna.dt)

sgrna.dt[, `:=`(seq = `5'->3' Sequence`,
                editSeq = `Edited 5'->3' Sequence`
                )]


# add this info for the other genes
sgrna.dt[!Gene %in% c("INTERGENIC","NON-TARGETING"), c('edit_index', 'editor', 'ref_base', 'alt_base') := findEditIndex(Seq=Guide, editSeq=editSeq, guideStrand = `Guide Strand`), by=.I]
# all of these guides are outside the edit window (bp 4-8)
sgrna.dt[Guide %in% noEditGuides, unique(edit_index)]

test.dt[Guide %in% noEditGuides,][,unique(edit_index)]
```


Test on all 4 combos
#cant confirm this as Ronalds set is wrong (edits not isolated to the defined edit window) expand across entire string weirdly!
```{r}
guides.dt[guide_strand == 'sense' & strand ==1] #TGTAAAACTTGCAAAGAATC
guides.dt[guide_strand == 'antisense' & strand ==1] #CATTGTTCTGATTCTTTGCA
guides.dt[guide_strand == 'sense' & strand ==-1] #ATTATATCTTCTTTTGCAGA
guides.dt[guide_strand == 'antisense' & strand ==-1] #CATTGTTCTGATTCTTTGCA




sgrna.dt[Guide %in% c('TGTAAAACTTGCAAAGAATC','CATTGTTCTGATTCTTTGCA', 'ATTATATCTTCTTTTGCAGA', 'CTGCAAAAGAAGATATAATC')]

getCodingSequenceEdit('TGTAAAACTTGCAAAGAATC', window_start = 4, window_end = 8, editor='bemax', guideStrand = 'sense') == 'TGTAAAATTTGCAAAGAATC' #TRUE
getCodingSequenceEdit('ATTATATCTTCTTTTGCAGA', window_start = 4, window_end = 8, editor='bemax', guideStrand = 'sense') == 'ATTATATTTTCTTTTGCAGA' # TRUE
getCodingSequenceEdit('CATTGTTCTGATTCTTTGCA', window_start = 4, window_end = 8, editor='abe8e', guideStrand = 'antisense')
getCodingSequenceEdit('CATTGTTCTGATTCTTTGCA', window_start = 4, window_end = 8, editor='bemax', guideStrand = 'antisense')


#bemax is C->T abe8e is A -> G
#seems good to me 
getCodingSequenceEdit('AACGTA', window_start = 3, window_end = 7, editor='bemax', guideStrand = 'sense')
```



```{r}

#if(length(refSet) != window_end - window_start)
  #  stop('see edit window selection')
  
guides.dt[guide == 'CATTGTTCTGATTCTTTGCA',]
  
  
  # get mismatch indices
  edit.idx <- which(refSet != editSet)
  editbase <- unique(editSet[edit.idx])
  print(editbase)
  
  #stopifnot(toupper(editbase) %in% c('T', 'G'))
  
  # sanity check compare to the number of edit socres we detect, if off abort
  if (length(edit.idx) != length(strsplit(editScores, ', ')[[1]]) )
    stop('Found different number of edits vs reported in the sgrna input file\n Offending guide: ', Seq)
  
  if (as.character(guideStrand) == '1'){
    
    return(list(index=edit.idx,
                editor=rep(ifelse(editbase %in% c('T','C'), 'bemax', 'abe8e'), length(edit.idx)),
                ref=refSet[edit.idx],
                alt=editSet[edit.idx]))
    
  } else if  (as.character(guideStrand) == '-1'){
    
    return(list(index=edit.idx,
                editor=rep(ifelse(editbase %in% c('T','C'), 'bemax', 'abe8e'), length(edit.idx)),
                ref=refSet[edit.idx],
                alt=editSet[edit.idx]))
  
  }
}



guides.dt[guide_strand == 'sense' & strand ==1] #TGTAAAACTTGCAAAGAATC
guides.dt[guide_strand == 'antisense' & strand ==1] #CATTGTTCTGATTCTTTGCA
guides.dt[guide_strand == 'sense' & strand ==-1] #TGTAAAACTTGCAAAGAATC
guides.dt[guide_strand == 'antisense' & strand ==-1] #CATTGTTCTGATTCTTTGCA
```



Only thing that should need to be provided for this is: edit window start, edit window end, guide strand and gene strand (still dont know what guide strand refers to here is it ref or relative to gene)
I think. write this to work with just the alignment info

```{r}
# lets play with this abit.. we have the guide and the edit seq


anno.dt

# getting 5' -> 3' edi

#' Need to reimplement; given a guideSequence, a window and and an editor, fund the pot
#' This is really a QC check vs a given file with an already provided edit sequence
# given a reference and editedSeq; first ensure len match, then get the differences (could use biostrings but may be better way)


# still need to figure out how to map index or best way to do it...
findEditIndex <- function(Seq, editSeq, guideStrand=NULL, editScores=NULL){
  
  if(nchar(Seq) != nchar(editSeq))
    stop('reference and edit sequences length mismatch. Aborting..')
  
  # if the edits are on the antisense, convert to sense (want in 5'->3' direction)
  if (as.character(guideStrand)== '-1'){
    Seq <- as.character(Biostrings::reverseComplement(Biostrings::DNAStringSet(Seq)))
  }
  
  print(Seq)
  print(editSeq)
  refSet <- strsplit(Seq,'')[[1]]; editSet <- strsplit(editSeq,'')[[1]]
  # get mismatch indices
  edit.idx <- which(refSet != editSet)
  editbase <- unique(editSet[edit.idx])
  print(editbase)
  
  #stopifnot(toupper(editbase) %in% c('T', 'G'))
  
  # sanity check compare to the number of edit socres we detect, if off abort
  if (length(edit.idx) != length(strsplit(editScores, ', ')[[1]]) )
    stop('Found different number of edits vs reported in the sgrna input file\n Offending guide: ', Seq)
  
  if (as.character(guideStrand) == '1'){
    
    return(list(index=edit.idx,
                editor=rep(ifelse(editbase %in% c('T','C'), 'bemax', 'abe8e'), length(edit.idx)),
                ref=refSet[edit.idx],
                alt=editSet[edit.idx]))
    
  } else if  (as.character(guideStrand) == '-1'){
    
    return(list(index=edit.idx,
                editor=rep(ifelse(editbase %in% c('T','C'), 'bemax', 'abe8e'), length(edit.idx)),
                ref=refSet[edit.idx],
                alt=editSet[edit.idx]))
  
  }
}



findEditIndex('CATTGTTCTGATTCTTTGCA', 'TGCAAAGAATCAAAACAATA',guideStrand = -1, editScores= '25.4, 0.2')

sgrna.dt[Guide == 'CATTGTTCTGATTCTTTGCA',]
as.data.table(findEditIndex(Seq='CATTGTTCTGATTCTTTGCA',editSeq = 'TGCAAAGAATCAAAACAATA', editScores = c('25.4, 0.2'),guideStrand = -1))
```


```{r}
# looks good
align.pos.dt[Guide %in% c('GTTCACCTGATGATGGTCGT', 'ACGACCATCATCAGGTGAAC'),]
align.out.dt[Guide %in% c('GTTCACCTGATGATGGTCGT', 'ACGACCATCATCAGGTGAAC'),]

#' Given dt of alignment coordinates and strand to reference and a window interval, extract the alignment coordinates
#' I think we want a range: editwindow start and end, this way we can map using the between function
#' Also we want a comma seperated list of the bases in this range I think...
#' If +, we want to 
#' 
#' 
#' Figure out best way of coding htis function: do we want to use a dt, or just refer to params? 
getEditWindowAInfo <- function(dt, windowStart, windowEnd){
  
   subdt <-  dt[, .(editWindowStart = pos_align_start+windowStart,
                    editWindowEnd   = pos_align_end+windowEnd,
                    posStrandRef    = ifelse(align_strand == '+', substr(Guide, windowStart, windowEnd), substr(getSeqReverseComplement(Guide), windowStart, windowEnd))
    )]
  
  return(subdt)
  
}

# apply this to each row of the dt
extractPosStrandRef <- function(guide, strand, start, end) {
    if (strand == '+') {
      substr(guide, start, end)
    } else {
      substr(getSeqReverseComplement(guide), start, end)
    }
}





getEditWindowInfo <- function(sequences, strand, windowStart, windowEnd) {
  
  
  # define a new DT with these elements
  dt <- data.table(Guide = sequences,
                   align_strand = strand,
                   pos_align_start=)
  
  de
  # Define a helper function to extract the substring based on strand
  extractPosStrandRef <- function(guide, strand, start, end) {
    if (strand == '+') {
      substr(guide, start, end)
    } else {
      substr(getSeqReverseComplement(guide), start, end)
    }
  }
  
  # Calculate edit window positions and apply the helper function row-wise
  dt[, `:=`(
    editWindowStart = pos_align_start + windowStart,
    editWindowEnd   = pos_align_end + windowEnd,
    posStrandRef    = extractPosStrandRef(Guide, align_strand, editWindowStart, editWindowEnd)
  )]
  
  return(dt)
}




getEditWindowInfo(align.pos.dt, windowStart = 4, windowEnd = 7)
edit.test[,]

test.align <- alignToReference(seqIn = align.in.dt$Guide, ref='GRCH38', chrToSearch = 'all', strand='both', nCores = 2)

align.out.dt[Guide %in% c('GTTCACCTGATGATGGTCGT', 'ACGACCATCATCAGGTGAAC'),]


179198853 - 179198834
19096726 - 19096707
```


**Not used right now**

**Todo**
1. Check the alignments - good
Next, identify the edit region region
Focus on the alignment stuff here; maybe better approach is to look for flanking sequences of the clinvar db?

**Checking alignments**
IMPORTANT: some of the guides occupy the same genomic coordinates, but are on opposite strands
I think safest approach is to map the guide sequences to both strands
By not collapsing guides to genomic intervals on +, we have guide-specific info to aid filtering (N off-target hits, edit efficiency etc)
Convert coordinates to + strand

```{r}
clinvar.dt[GeneSymbol == 'PTEN', .(GeneSymbol, Name, Start,PositionVCF)][order(Start)]
sgrna.dt[Position == 87933145,]


# 834 guides (naively) have a clinvar editSite
clinvar.dt$Start %in% sgrna.dt$Position

clinvar.dt[Start %in% sgrna.dt$Position, .(GeneSymbol, Start)] # take 87933145


sgrna.dt[Guide  %in% c('GTTCACCTGATGATGGTCGT', 'ACGACCATCATCAGGTGAAC')]
align.pos.dt[Guide == 'GTTCACCTGATGATGGTCGT',]

align.pos.dt <- alignToReference(seqIn = align.in.dt$Guide, ref='GRCH38', chrToSearch = 'all', strand='both', nCores = 2)

clinvar.dt %>%  head()


sgrna.dt[Gene == 'PTEN',]


align.pos.dt


anno.dt
```

Testing why collapsing misses guides
```{r}
# same sequences recovered in both; just need to ensure everything is upper case
toupper(align.plus.dt$Guide) %>%  unique() %>%  length()
toupper(align.in.dt$SeqToAlign) %>%  unique() %>% length()
toupper(align.out.dt$Guide) %>%  unique() %>%  length()
toupper(align.in.dt$Guide) %>%  unique() %>% length()

# reports what is in x that is missing in y 
setdiff(toupper(align.plus.dt$Guide), toupper(align.in.dt$SeqToAlign))

# find guides hitting same genomic location
oppositeStr.guides <- sgrna.dt[!is.na(Position),][duplicated(Position)][, unique(toupper(Guide))]

test.dt <- merge(align.plus.dt[,.N, by=(Guide)][,.(SeqToAlign = toupper(Guide), nHits=N)], align.in.dt[,.(Guide=toupper(Guide), SeqToAlign = toupper(SeqToAlign), strand, `Guide Strand`)], by='SeqToAlign', all.x=T)

test.dt[duplicated(SeqToAlign), unique(Guide)] %in% oppositeStr.guides
```

report pos only on + strand

```{r}
test.align <- alignToReference(seqIn = align.in.dt$Guide, ref='GRCH38', chrToSearch = 'all', strand='both', nCores = 2)
```



```{r}
test.align <- alignToReference(seqIn = align.in.dt$Guide, ref='GRCH38', chrToSearch = 'all', strand='both', nCores = 2)


align.in.dt[grep('[a-z]', Guide)]

# bear in mind these are only perfect matches.... not sure about guide specificity, but maybe should modify to tolerate 1 mismatch
align.out.dt  <- alignToReference(seqIn = align.in.dt$Guide, ref='GRCH38', chrToSearch = 'all', strand='both', nCores = 2)

# all the same set, just ~100 lowercase in input, so need to convert to upper for merging
setdiff(toupper(align.in.dt$Guide), unique(align.out.dt$Guide))




align.out.dt[!Guide %in% align.in.dt$Guide,]

align.in.dt$Guide

which(align.in.dt$Guide %in% unique(align.out.dt$Guide)) %>% sum()
#  use this to evalulate my seq conversion; what criteria am I missing
align.plus.dt <- alignToReference(seqIn = align.in.dt$SeqToAlign, ref='GRCH38', chrToSearch = 'all', strand='+', nCores = 2)
#align.plus.alt.dt <- alignToReference(seqIn = align.in.dt$SeqToAlign2, ref='GRCH38', chrToSearch = 'all', strand='+', nCores = 2)

align.out.dt[,.N, by=Guide][order(-N)]


align.out.dt
align.plus.dt[,.N, by=Guide][order(-N)] 

guide.meta.dt <- align.in.dt[,.(Guide=(Guide), SeqToAlign, `Guide Strand`,strand, chromosome_name)]
guide.meta.dt[grepl('[a-z]', Guide),]

align.in.dt[!SeqToAlign %in% align.plus.dt[,.N, by=Guide]$Guide, ]

align.in.dt %>% nrow()
merge(x=guide.meta.dt,y=align.plus.dt[,.(nHits=.N),by=Guide], by.x='SeqToAlign', by.y='Guide', all.x=T, all.y=T) %>% nrow()


# interesting... all of the guides align, but >600 more than once with perfect alignment... not great guide selection...
align.out.dt[,.N, by=Guide][N > 1][order(-N)]
align.plus.dt[,.N, by=Guide][N > 1][order(-N)]
```

Functions work... but optimisation needed...
```{r}

#' Function to align vector of nucleotide seqs against host genome (currenlty only GRCh38 supported)
#' Want to provide a strand argument; that way can speed up searches if strand is known (but better coverage of off-site hits here?)
#' Limitation is sacrifice of flexibilty for speed. currently using a dictionary DS forcing seq lengths to be equal and allowing no mismatches in search, but suited to guide mapping (I think)
#' max ncores = detectCores() - 1
#' If not specified, runs single stranded 
alignToReference <- function(seqIn, ref='GRCH38', chrToSearch, strand, nCores=NULL){
   require(BSgenome.Hsapiens.NCBI.GRCh38)
   require(parallel)
  
  # requires the NCBI reference for the alignment (hopefully aligns with clinvar...)
  # other option is to go to clinvar, pull out flanking regions of edits and do PW alignments to that but prob slower   
  if (toupper(ref) != 'GRCH38')
    stop('Currently only NCBI GRCh38 reference genome is supported')

  ref <- BSgenome.Hsapiens.NCBI.GRCh38
  
  if (toupper(chrToSearch) == 'ALL')
    chrToSearch <- names(ref)[1:24]
  
  message("Targeting ", metadata(ref)$genome, " chromosomes ", paste(chrToSearch, collapse=", ")) 
  
  #  preprocess as dictionary for faster searching (no mismatches to DB allowed and seqIn must be equal ength)
  pdict <- PDict(seqIn)

  if (is.null(nCores)) {
    nCores <-  1
    message('Number of cores not specified. Running single-threaded')
  
  } else if (!is.double(nCores)) {
    stop('nCores must be an integer if set')
    
  } else if (nCores >= detectCores()) {
    nCores <- detectCores() - 2
    message('Number of cores exceeds system specs. Setting nCores at ', nCores) 
  }
  
  if (is.null(strand) | !toupper(strand) %in% c('+','-','BOTH')){
    
  stop('Reference strand for alignment must be set. Please select either "+","-", or "both"')
  } else if (strand == '+'){
    
   pos.aligns <- mclapply(chrToSearch, function(seqname){
   
   subject <- ref[[seqname]]
   message("Finding all hits in ", strand, " strand of chromosome ", seqname)
   mindex <- matchPDict(pdict, subject) # fast match but not allowing mismatches
   matches <- as.data.table(extractAllMatches(subject, mindex))
    
   matches[, `:=`(chromosome_name = seqname,
                   align_strand = strand)]
  }, mc.cores=nCores) %>% rbindlist()
  
  message('Aligned ', (length(unique(pos.aligns$seq))/length(unique(seqIn)))*100,'% of sequences')
  #message('Failed to align', paste0(setdiff(toupper(seqIn), pos.aligns$seq), collapse=','))
  return(pos.aligns[, .(Guide=seq, align_strand, pos_align_start=start, pos_align_end=end, chromosome_name)])
  } else if (strand == '-'){
   
   neg.aligns <- mclapply(chrToSearch, function(seqname){
   
   subject <- reverseComplement(ref[[seqname]])
   chr_length <- length(subject)
   
   message("Finding all hits in ", strand, " strand of chromosome ", seqname)
   mindex <- matchPDict(pdict, subject) # fast match but not allowing mismatches
   matches <- as.data.table(extractAllMatches(subject, mindex))
    
   matches[, `:=`(chromosome_name = seqname,
                  align_strand = strand,
                  pos_align_start=chr_length - end + 1,
                  pos_align_end=chr_length - start + 1
                  )]
  }, mc.cores=nCores) %>% rbindlist() 
  
  message('Aligned ', (length(unique(neg.aligns$seq))/length(unique(seqIn)))*100,'% of sequences')
  #message('Failed to align', paste0(setdiff(toupper(seqIn), neg.aligns$seq), collapse=','))
  message('Converting - strand mapping coordinates to + strand..')
  return(neg.aligns[, .(Guide=seq, align_strand, pos_align_start, pos_align_end, chromosome_name)])  
  } else {
    
   pos.aligns <- mclapply(chrToSearch, function(seqname){
   
   subject <- ref[[seqname]]
   message("Finding all hits in ", strand, " strand of chromosome ", seqname)
   mindex <- matchPDict(pdict, subject) # fast match but not allowing mismatches
   matches <- as.data.table(extractAllMatches(subject, mindex))
    
   matches[, `:=`(chromosome_name = seqname,
                   align_strand = "+")]
  }, mc.cores=nCores) %>% rbindlist()    
 
   neg.aligns <- mclapply(chrToSearch, function(seqname){
    
   subject <- reverseComplement(ref[[seqname]])
   chr_length <- length(subject)
   
   message("Finding all hits in - strand of chromosome ", seqname)
   mindex <- matchPDict(pdict, subject) # fast match but not allowing mismatches
   matches <- as.data.table(extractAllMatches(subject, mindex))
    
   matches[, `:=`(chromosome_name = seqname,
                  align_strand = '-',
                  pos_align_start=chr_length - end + 1,
                  pos_align_end=chr_length - start + 1
                  )]
  }, mc.cores=nCores) %>% rbindlist()
  
   message('Converting - strand mapping coordinates to + strand..')
  all.aligns <- rbind(pos.aligns[, .(Guide=seq, align_strand, pos_align_start=start, pos_align_end=end, chromosome_name)],
                      neg.aligns[, .(Guide=seq, align_strand,  pos_align_start, pos_align_end, chromosome_name)])
  
  message('Aligned ', (length(unique(all.aligns$Guide))/length(unique(seqIn)))*100,'% of sequences')
  #message('Failed to align', paste0(setdiff(toupper(seqIn), all.aligns$Guide), collapse=','))
  return(all.aligns)
  }
}

```
Some todos tomorrow:
Figure out issue with seqConversion : map to criteria in the sgRNA dt and find what I am missing
Make a table of n hits; anything with more than 1 perfect match in reference (and perhaps a low efficiency score?) we can try label as poor hits...t-test on LFC values between groups?

How can I use this info to map to clinvar? First I will need to check pos, and then check ref and alt bases maybe? May need to also align clinvar to the same reference to 'align' genomes..


I think for our testing, it might be interesting to also include sgRNA efficiency and nHitsGenome as predictors in our glm? maybe use LRT to compare a simplified to this.If they are good predictors, maybe we need another approach to differential testing (Bayesian, could we include these as priors maybe?)





DO MTC for both datasets
I think we can move forward with this set; lets see where these hits lie in the gene; annotate and redo the plots..

```{r}
de.dt[adj.p < 0.1 & abs(log2FoldChange) > 1,.N,by=contrast]
lrt.de.dt[, adj.p := p.adjust(pvalue), by=.(editor, contrast)]
lrt.de.dt[adj.p < 0.1 & abs(log2FoldChange) > 1,.N, by=contrast]


# at this threshold we expect approx 40 guides to be called differentially expressed by chance
# FDR at 1% we will call significant set
lrt.de.dt[padj < 0.1 & abs(log2FoldChange) > 1,.N, by=contrast]
de.dt[padj < 0.1 & abs(log2FoldChange) > 1,.N, by=contrast]

```


```{r}
dds <- DESeq(dds)
resultsNames(dds)


metadata$group %>%  unique()

deseq2.test <- results(dds, contrast=c("group","abe8e_Alpelisib_22","abe8e_librep_0"))

deseq2.test <- as.data.table(deseq2.test, keep.rownames=T)

deseq2.test[, sig := 'not']
deseq2.test[abs(log2FoldChange) >= 1 & padj < 0.05, sig := ifelse(log2FoldChange > 0, 'up', 'down')]

deseq2.test
```


First, we need to prefilter our dataset
Find rows with zeros, then maybe find rows

# build control and treatment matrices

```{r}

makeMAGECKmatrix <- function(mat, ctrlRegex, treatRegex){
  
  controlSamples <- grep(ctrlRegex, colnames(mat), value=T)
  treatSamples <- grep(treatRegex, colnames(mat), value=T)
  
  if(length(controlSamples) < 1 | length(treatSamples) < 1)
  stop('Control and/or treatment samples not found. Please check regex patterns')
  
  if(length(controlSamples) != length(treatSamples))
  message('Warning: Different number of samples in control and treatment groups')
  
  message('Found ', length(controlSamples), ' control samples in matrix: ', paste(controlSamples, collapse=','))
  message('Control sample indexes: ', paste(match(controlSamples,colnames(mat)), collapse=','))
  message('Found ', length(treatSamples), ' treatment samples in matrix: ', paste(treatSamples, collapse=','))
  message('Treatment sample indexes: ',paste(match(treatSamples,colnames(mat)), collapse=','))

  # extracting matrix 
  subMat <- mat[, c(controlSamples, treatSamples)]
  return(subMat)
}


#' function to filter guides with low counts
#'Simple function; look within each group being compared, and if either has less than the specified count threshold, drop this guide
# by default filters any rows with counts that dont meet threhsold, but can supply control or treatment regex to filter by these groups
filterLowCountGuides <- function(mat, countThreshold=100, type='all', ctrlRegex=NULL, treatRegex=NULL){
  
  if (type =='all'){
    
  countFilter <- apply(mat, 1, function(x){ any(x < countThreshold) })
  message('Removing ',  sum(countFilter == T), ' guides with counts less than ', countThreshold, ' in any samples')
  return(mat[!countFilter,])
    
  } else if (type == 'control'){
    
    if(is.null(ctrlRegex))
      stop('Control regex pattern must be specified if using type=control')
    
    submat <- mat[, grepl(ctrlRegex, colnames(mat))]
    if (is.null(colnames(submat)))
      stop('columns not found matching control regex pattern')
    
    countFilter <- apply(submat, 1, function(x){ any(x < countThreshold) })
    message('Removing ',  sum(countFilter == T), ' guides with counts less than ', countThreshold, ' reads in any control samples')
    return(mat[!countFilter,])
    
  } else if (type == 'treatment'){
    
    if(is.null(treatRegex))
      stop('Treatment regex pattern must be specified if using type=treatment')
    
     submat <- mat[, grepl(treatRegex, colnames(mat))]
     if (is.null(colnames(submat)))
       stop('columns not found matching treatment regex pattern')
     
    countFilter <- apply(submat, 1, function(x){ any(x < countThreshold) })
    message('Removing ',  sum(countFilter == T), ' guides with counts less than ', countThreshold, ' reads in any treatment samples')
    return(mat[!countFilter,])
    
  } else if (type == 'both'){
    
    if(is.null(treatRegex) | is.null(ctrlRegex))
      stop('If type="both" you must specify both a control and treatment plot')
    
    cmat <- mat[, grepl(ctrlRegex, colnames(mat))]
    tmat <- mat[, grepl(treatRegex, colnames(mat))]
    
    
    if (is.null(colnames(cmat)) | is.null(colnames(tmat)))
       stop('columns not found matching both control & treatment regex patterns')
    submat <- cbind(cmat, tmat)

    countFilter <- apply(submat, 1, function(x){ any(x < countThreshold) })
    message('Removing ',  sum(countFilter == T), ' guides with counts less than ', countThreshold, ' reads in either control or treatment samples')
    return(mat[!countFilter,])    
    
    
  } else {
    
    stop('Type ', type, 'not supported. Please specify either "all", "control", "treatment", "both" ')
  }
}
```

function to normalize counts using the DESeq2 TMM method - DONE but check to implement other methods too maybe 
Can we improve the variance estimation? Expand to all samples used in the contrast?
```{r}
# round the counts 
test.mat <- round(mat.list[[1]])

sampleNormalization <- function(mat, sgControls=NULL, diagnostics=T, returnSizeFactors=F){
  
  if (is.null(sgControls)){
    
    message('Performing normalization on all guides')
    message(nrow(mat), ' guides used for normalization')
    
    n <- ncol(mat); p <- nrow(mat)
    
    # calculate the rowwise gemmetric mean
    # faster method https://stackoverflow.com/questions/2602583/geometric-mean-is-there-a-built-in
    geoMeans <- apply(mat, 1, function(r){ exp(mean(log(r+1))) }) # can take the mean of the log-scaled values and then just raise to the exponent.Add pseudocount to prevent Inf...
    #geoMeans2 <- apply(mat, 1, function(r){ exp(sum(log(r+1))*1/n) }) # mageck calc. Same value
    
    # divide the original counts by the geoMean
    # in linear scale for now as in MAGECK...
    scaled.mat <- sweep(mat, 1, geoMeans, '/')
    
    message('Calculating normalization factors..')
    normFactors <- apply(scaled.mat, 2, median, na.rm=T)
    
  } else if (sum(sgControls %in% rownames(mat)) < 10){
    
    stop('Insufficient number of control guides found in matrix for normalization. Please increase number of guides to >= 10 or run normalization on all guides')
    
  } else {
    message('Using control guides to estimate sample scaling factors')
    ctrlmat <- mat[rownames(mat) %in% sgControls,]
    message('Found ', nrow(ctrlmat),' control guides inn matrix...')
    geoMeans <- apply(ctrlmat, 1, function(r){ exp(mean(log(r+1))) })
    scaled.mat <- sweep(ctrlmat, 1, geoMeans, '/')
    
    message('Calculating normalization factors..')
    normFactors <- apply(scaled.mat, 2, median, na.rm=T)
    
  }
    # print diagnostic plots to screen for user to inspect the normalization process
    if (diagnostics){
      
      dt <- reshape2::melt(mat) %>% 
        as.data.table()
      setnames(dt, new=c('guide', 'sample', 'counts'))
      
      # norm 
      norm.dt <- data.table(sample = names(normFactors),
                            offset = normFactors)
      
     dt <- merge(dt, norm.dt, by='sample', all.x=T, all.y=T)
     dt[, normcounts := counts/offset, by=.(sample,guide)]
     
     scaled.dt <- reshape2::melt(scaled.mat) %>% 
        as.data.table()
      setnames(scaled.dt, new=c('guide', 'sample', 'ratios'))
      
      scaled.dt <- merge(scaled.dt, norm.dt, by='sample', all.x=T, all.y=T)
     
     g <- ggplot(dt, aes(x=sample, y=log2(counts+1))) +
       geom_boxplot(aes(color='raw counts'), alpha=0.6) +
       geom_boxplot(aes(x=sample, y=log2(normcounts+1), color='norm counts')) +
       ggtitle('Count distributions') +
       scale_color_manual(values=c('raw counts'='black', 'norm counts'='firebrick')) +
       theme_bw() +
       theme(axis.text.x=element_text(angle=90))
    
     p <-  ggplot(norm.dt, aes(x=sample, y=offset)) +
       geom_bar(stat='Identity', fill='steelblue') +
       ggtitle('Scaling factors') +
       theme_bw() +
       theme(axis.text.x=element_text(angle=90))
     
     q <- ggplot(scaled.dt, aes(x=ratios)) +
       geom_histogram(bins=60) +
       geom_vline(aes(xintercept=offset),color='firebrick') +
       facet_wrap(~sample, ncol=3) +
       ggtitle('') +
       theme_bw() +
       theme(axis.text.x=element_text(angle=90))
     
     print(g)
     print(p)
     print(q)
    }
    
    message('Normalizing counts...')
    
    if (returnSizeFactors == F){
      
      return(sweep(mat, 2, normFactors, '/'))
      
    } else{
      
      return(list(normMat = sweep(mat, 2, normFactors, '/'),
                  normFactors = normFactors))
    }
}


sampleNormalization(mat=test.mat, returnSizeFactors = T, diagnostics=T, sgControls =sgControls)
```


Not used...

First to do; lets look at de analysis of just the treatment and control conditions:
Alp 22 vs librep 0 and compare
```{r}
reduced.mat.list <- lapply(mat.list, function(x){
  
  cols.oi <- grep('librep|Alpelisib_22', colnames(x), value=T)
  return(x[, cols.oi])
  
})

 reduced.meta.list <- lapply(meta.list, function(x){
  
  cols.oi <- grep('librep|Alpelisib_22', rownames(x), value=T)
  return(x[rownames(x) %in% cols.oi,])
})
 
#looks good
colnames(reduced.mat.list[[1]]) == rownames(reduced.meta.list[[1]])
colnames(reduced.mat.list[[2]]) == rownames(reduced.meta.list[[2]])

```

run DESeq2 on the seperated datasets (set size factors to 1 to avoid re-normalizing)

```{r}
# first run DESeq2 with the full set on the two editors seperately
reduced.deseq.list <-lapply(names(reduced.mat.list), function(x,y,i){
  
  dds <- DESeqDataSetFromMatrix(countData = round(x[[i]]),
                              colData = y[[i]],
                              design = ~condition)
  
  dds <- estimateSizeFactors(dds)

  # run DESeq2 w/o normalization
  # replace the size factors
  sizeFactors(dds) <- replace(sizeFactors(dds), 1:length(sizeFactors(dds)), 1)
  return(dds)
},x=reduced.mat.list, y=reduced.meta.list)

names(reduced.deseq.list) <-  names(reduced.mat.list)
```


Lets filter out the sets with low counts; want at least 10 reads in 75% of the data

```{r}
reduced.deseq.list <- lapply(names(reduced.deseq.list), function(x,i){
  
  # this is the ori 75% but be more stringent for now
  #keep <- rowSums(counts(x[[i]]) >= 10) >= 3  
  keep <- rowSums(counts(x[[i]]) >= 10) == 4
  dds <-  x[[i]][keep,]
  
  message('Retaining ', nrow(dds), ' guides ', 'from ', nrow(counts(x[[i]])))
  return(dds)
  
},x=reduced.deseq.list)

names(reduced.deseq.list) <-  names(reduced.mat.list)
```

Save the two deseq objecs
Skip for now 

```{r, eval=F}
lapply(names(deseq.list), function(x,i){
  #x[[i]]
  #saveRDS(x[[i]], file=paste0("/Users/martingordon/Documents/projects/101224_RBabu_CRISPRe_PIK3CA/161024_PWComparisons_DESeq2_data/", i, '.dds.obj'))
},x=deseq.list)
```

Run the differental comparison on the two groups
```{r}
# here we are basically testing if the addition of a 'condition' term produces a model with a better 'fit' than the basic model

reduced.lrt.de.list <- lapply(reduced.deseq.list, function(x){
  
  dds <- DESeq(x, test='LRT', reduced=~1)
  
  contrasts.oi<- grep('Intercept', resultsNames(dds), invert=T, value = T)
  print(contrasts.oi)
  
  all.res <- lapply(contrasts.oi, function(n){
    
    res <- results(dds, name=n) %>% 
      as.data.table(., keep.rownames=T) %>% 
      .[, contrast := n]
  }) %>% rbindlist()
  
  
  return(all.res)
})

reduced.lrt.de.dt <- rbindlist(reduced.lrt.de.list, idcol='editor')


reduced.de.list  <- lapply(reduced.deseq.list, function(x){
  
  dds <- DESeq(x)
  
  contrasts.oi<- grep('Intercept', resultsNames(dds), invert=T, value = T)
  
  all.res <- lapply(contrasts.oi, function(n){
    
    res <- results(dds, name=n) %>% 
      as.data.table(., keep.rownames=T) %>% 
      .[, contrast := n]
  }) %>% rbindlist()
})

reduced.de.dt <- rbindlist(reduced.de.list, idcol='editor')


setnames(reduced.de.dt, old='rn', new='sgRNA')
setnames(reduced.lrt.de.dt, old='rn', new='sgRNA')

reduced.de.list <- list('wald'=reduced.de.dt,
                'LRT'= reduced.lrt.de.dt)
```
Annoate 
```{r}
lapply(reduced.de.list, function(x){
  
  x[, sig := 'not']
  x[abs(log2FoldChange) > 1 & pvalue < 0.005, sig := ifelse(log2FoldChange > 0 ,'up', 'down')]
})


# need to add gene info to the list
# write out the results to file. For now lets stick with the LFC vs control group
lapply(names(reduced.de.list), function(x, i){

  dt <- merge(x[[i]], gene.info, by='sgRNA', all.x=T)
  dt[, contrast := sub('condition_', '',contrast)]
  fwrite(dt, ScriptAndDatedFileName(paste0(i,'deseq2.reducedTest.Alp22vsT0.csv')))
  
},x=reduced.de.list)


reduced.de.dt <- fread('~/Documents/projects/101224_RBabu_CRISPRe_PIK3CA/161024_PWComparisons_DESeq2_data/2024_10_31_walddeseq2.reducedTest.Alp22vsT0.csv')
reduced.de.dt[, numeratorTimepoint := factor(gsub('_', '', str_extract('_[027]+_', contrast)), levels=c('0','7','22'))]
reduced.de.dt[, direction := ifelse(log2FoldChange > 0, 'up', 'down')]
reduced.de.dt[, group := paste(editor, contrast)]


```


Lets see what the counts look like; less for reduced dataset

```{r}
g <- ggplot(reduced.de.dt[,.N, by=.(sig, contrast, editor, numeratorTimepoint)][sig != 'not',], aes(x=reorder(contrast, as.numeric(numeratorTimepoint)), y=N, fill=sig)) +
  geom_bar(stat='Identity') +
  facet_wrap(~editor, scales='free') +
  ggtitle('Significant sgRNA (Log2FC >= 1 & FDR < 0.1)') +
  scale_fill_manual(values=c('up'='#990033', 'down'='#336699')) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=90, size=7))
g
```
```{r}
g <- ggplot(reduced.de.dt[,.N, by=.(sig, contrast, editor, numeratorTimepoint)][sig != 'not',], aes(x=reorder(contrast, as.numeric(numeratorTimepoint)), y=N, fill=sig)) +
  geom_bar(stat='Identity') +
  facet_wrap(~editor, scales='free') +
  ggtitle('Significant sgRNA (Log2FC >= 1 & FDR < 0.1)') +
  scale_fill_manual(values=c('up'='#990033', 'down'='#336699')) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=90, size=7))
g
BackupAsPDF(g, 'NsigHits.reducedSet_Apl22_vsT0')
```
Show the volcanoplot and color by 

Looks like might be some more hits, but far less than when including both sets..
What about including all the samples at once? Maybe not a good idea; different edits so I think we consider these different experiments, although, different controls shouldnt impact...
Maybe if we are interested in region, we should look per comparisona and pool editors? Try both approaches and compare...

```{r}


g <- ggplot(reduced.de.list[['LRT']][,.N, by=.(sig, contrast, editor)][sig != 'not',], aes(x=contrast, y=N, fill=sig)) +
  geom_bar(stat='Identity') +
  facet_wrap(~editor, scales='free') +
  ggtitle('Significant sgRNA (Log2FC >= 1 & FDR < 0.1)') +
  scale_fill_manual(values=c('up'='#990033', 'down'='#336699')) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=90, size=7))
g


reduced.lrt.de.dt


g <- ggplot(reduced.de.dt[,.N, by=.(sig=ifelse(padj < 0.05 & log2FoldChange >= 1, 'up', ifelse(padj < 0.05 & log2FoldChange <= -1, 'down', 'not')), contrast, editor)][sig != 'not',], aes(x=contrast, y=N, fill=sig)) +
  geom_bar(stat='Identity') +
  facet_wrap(~editor, scales='free') +
  ggtitle('Significant sgRNA (Log2FC >= 1 & FDR < 0.1)') +
  scale_fill_manual(values=c('up'='#990033', 'down'='#336699')) +
  theme_bw() +
  theme(axis.text.x = element_text(angle=90, size=7))
g


result(lfcThreshold)
```


Get rid of these low count guides, want things with at least 10 reads in 80% of samples

```{r}
keep <- rowSums(counts(dds) >= 10) >= 23
dds <- dds[keep,]
```

run DESEq2

```{r}
dds <- DESeq(dds)
resultsNames(dds)


metadata$group %>%  unique()

deseq2.test <- results(dds, contrast=c("group","abe8e_Alpelisib_22","abe8e_librep_0"))

deseq2.test <- as.data.table(deseq2.test, keep.rownames=T)

deseq2.test[, sig := 'not']
deseq2.test[abs(log2FoldChange) >= 1 & padj < 0.05, sig := ifelse(log2FoldChange > 0, 'up', 'down')]

deseq2.test
```

Issue here might be our variance calculation... maybe we need to subset to the abe8e/bemax groups seperately... I think its best to leave these comparisons until tomorrow, and regenerate the code for the plots, the idea being 
```{r}
g <- ggplot(deseq2.test, aes(x=log2FoldChange, y=-log10(padj), color=sig)) +
  geom_point() +
  ggtitle("abe8e_Alpelisib_22 vs abe8e_librep_0") +
  scale_color_manual(values=c('down'='blue', 'up'='red', 'not'='grey'))

BackupAsPDF(g, 'DESeq2.firstPass')
```
```{r}

```


old functions

```{r}

findEditIndex <- function(Seq, editSeq, guideStrand=NULL, editScores=NULL){
  
  if(nchar(Seq) != nchar(editSeq))
    stop('reference and edit sequences length mismatch. Aborting..')
  
  if (as.character(guideStrand) %in% c('-1','1')){
    guideStrand <- ifelse(guideStrand == '-1', 'antisense', 'sense')
  }
  
  # if the edits are on the antisense, convert to sense (want in 5'->3' direction)
  if (as.character(guideStrand)== 'antisense'){
    Seq <- as.character(Biostrings::reverseComplement(Biostrings::DNAStringSet(Seq)))
  }

  refSet <- strsplit(Seq,'')[[1]]; editSet <- strsplit(editSeq,'')[[1]]
  # get mismatch indices
  edit.idx <- which(refSet != editSet)
  editbase <- unique(editSet[edit.idx])
  
  #stopifnot(toupper(editbase) %in% c('T', 'G'))
  
  # sanity check compare to the number of edit socres we detect, if off abort
  if (!is.null(editScores)){
    
    if (length(edit.idx) != length(strsplit(editScores, ', ')[[1]]) )
      stop('Found different number of edits vs reported in the sgrna input file\n Offending guide: ', Seq)
  }
  
  if (as.character(guideStrand) == 'sense'){
    
    return(list(index=paste(edit.idx,collapse=';'),
                #editor=paste(rep(ifelse(editbase %in% c('T'), 'bemax', 'abe8e'), length(edit.idx)), collapse = ';'),
                editor=paste(ifelse(editbase %in% c('T'), 'bemax', 'abe8e'), collapse=';'),
                ref=paste(refSet[edit.idx], collapse=';'),
                alt=paste(editSet[edit.idx], collapse=';')))
    
  } else if  (as.character(guideStrand) == 'antisense'){
    
    return(list(index=paste(edit.idx,collapse=';'),
                #editor=paste(rep(ifelse(editbase %in% c('A'), 'bemax', 'abe8e'), length(edit.idx)), collapse = ';'),
                editor=paste(ifelse(editbase %in% c('A'), 'bemax', 'abe8e'), collapse=';'),
                ref=paste(refSet[edit.idx], collapse=';'),
                alt=paste(editSet[edit.idx], collapse=';')))
  }
}

```