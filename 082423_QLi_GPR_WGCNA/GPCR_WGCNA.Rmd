---
title: "wgcna_gpcr"
author: "Martin Gordon"
date: "2023-08-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

15/09/23
The matrix used to generate the 11 receptor data is saved under './output/gpcr.11.receptors.adj.mat.Rdata'
Module assignments saved under './output/gpcr.11.receptors.moduleAssignment.Rdata'
#saveRDS(adj.mat, file='./output/gpcr.11.receptors.adj.mat.Rdata')
#saveRDS(modules.adj,file = './output/gpcr.11.receptors.moduleAssignment.Rdata')
#saveRDS(sig.p.mat,file = './output/gpcr.11.receptors.exp.mat.Rdata') # the expression matrix used as input for each of these

Return to this to clean the clusters; for now try find the eigengenes in each module

```{r}
library(data.table)
library(ggplot2)
library(ComplexHeatmap)
library(WGCNA)
library(magrittr)
library(preprocessCore) # quantile normalisation
library(stringr)
library(matrixStats)
library(simplifyEnrichment)
library(fmsb)
library(readxl)
library(ggbeeswarm)
library(ggrepel)

source("/Users/martingordon/Documents/utils/bp_utils/ManageScriptData.R")
source("/Users/martingordon/Documents/utils//bp_utils/LinearModels.R")
source("/Users/martingordon/Documents/utils/bp_utils/UniprotIDMapping.R")
source ("/Users/martingordon/Documents/utils/bp_utils/enrichmentTestFunctions.R")
```
28-08-23 
---
No longer quantile normalising as it is removing too much variance


## WGCNA GPCR proteins

```{r}
# read in exp data
p.quant <- fread('data/2022_08_17_ProteinLevelData.lib.csv.gz')

# read in DEA results for filtering
mss <- fread('data/2022_08_31_NiceFitsPower3.csv')

p.quant$GROUP %>%  unique()
```


Inspect the raw data

```{r}
str(p.quant)
```
Creating afew new id cols

```{r}

# fix the groups with an underscore in them MOR_LG and MOR_DAMGO to MOR.DAMGO
p.quant[, GROUP := gsub ("_([A-Z])", ".\\1", GROUP)]
# add some new identifier cols
p.quant[, `:=`(timeStr = str_extract(GROUP,'[0-9]{2}$'),
               receptor = gsub("_[0-9]{2}$", '', p.quant$GROUP)
               )]
```

Does this data need a second round of normalisation?
Assumption is the data is normalised
```{r}
group.noi <- p.quant[!GROUP %like% c("DOR|KOR|MOR|MRX2|MRX4|NK1R|NPFFR1|NPY1R|PTGER1|PTGER4|QRFPR|DOR"),unique(GROUP)]
group.noi

p.quant <- p.quant[!GROUP %in% group.noi, ]
p.quant <- p.quant[!GROUP %like% "MOR.LG94",]

p.quant$GROUP %>%  unique()
```

```{r}
g <- ggplot(p.quant, aes(x=interaction(GROUP,SUBJECT), y=LogIntensities, fill=receptor)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle=90))
g
BackupAsPDF(g, 'intensity.boxplots.')
```
Difference in expression levels of the DOR samples
Lets try correct for this using Quantile normalization; over correction?

```{r}
# convert p.quant to matrix
p.mat <- dcast(p.quant, Protein~GROUP+SUBJECT, value.var = 'LogIntensities') %>%  as.matrix(rownames="Protein")


# perform quanitle normalization on the data
#p.mat <- normalize.quantiles(p.mat, keep.names = T)
```

```{r}
#plot norm distributions
g <- melt(p.mat, na.rm=FALSE, value.name= 'LogIntensities', id=tstrstrsplit(colnames(p.mat))) %>% 
  as.data.table() %>% 
  .[, cond := tstrsplit(Var2, '_[0-9]{2}_batch.[0-9]{2}', keep=1)] %>% 
  .[, batch := str_extract(Var2, 'batch.[0-9]{2}')] %>% 
  .[, receptor :=  gsub("_[0-9]{2}.+$", '', Var2)] %>% 
  ggplot(aes(x=Var2, y=LogIntensities, fill=receptor)) + geom_boxplot() +   theme(axis.text.x = element_text(angle=90,size=4))

g
BackupAsPDF(g, 'q.norm.boxplot.', dimensions = c(7,7))

```

```{r}
g <- p.quant[, .N, by=.(GROUP,SUBJECT)] %>% 
  ggplot(aes(x=interaction(GROUP,SUBJECT),y=N, fill=GROUP)) + geom_bar(stat='Identity')
g

BackupAsPDF(g, 'n.proteins.')
```

Feature selection
-----

First need to handle missing values... if we just use complete.cases, we lose 45% of our data
over correction; check for n rows with more than 33% of samples missing; remove these
Receptor GROUPs? maybe use this to set threshold


```{r}
# 45% lost with 'full set'
nrow(p.mat)
nrow(p.mat[complete.cases(p.mat),])
1 - nrow(p.mat[complete.cases(p.mat),])/nrow(p.mat)

# remove rows with more than 33% missing values
p.mat.f  <- p.mat[which(rowMeans(!is.na(p.mat)) > 0.66), ] # only keep prots present in 2/3 of the dataset

dim(p.mat.f)
```

Remove low variance features, then consider how to handle missing values
For now taking top 75% of genes ranked on variability


```{r}
p.mat.var <- rowVars(p.mat.f, na.rm=T) %>%  
  data.table(prots = names(.), var=.) %>% 
  .[order(var, decreasing = F)]

prots.oi <- p.mat.var[var > quantile(p.mat.var$var, probs=.25), prots]

p.mat.f <- p.mat.f[rownames(p.mat.f) %in% prots.oi,]
dim(p.mat.f)

```

Cluster w/o controlling for batch first  to visualise

Some issues with missing genes for DOR receptor

```{r}
clusterwNa <- function(mat, na.val=0, ...){
  
  mat[is.na(mat)] <- na.val
  return(hclust(dist(mat)))
}

hm <- Heatmap(p.mat.f, cluster_rows = T, cluster_columns = F, na_col = 'darkgrey', column_split = tstrsplit(colnames(p.mat.f), '_', keep=1), row_title=sprintf('%s proteins', nrow(p.mat.f)), show_row_names = F, column_names_gp = gpar(fontsize=5), column_title_gp = gpar(fontsize = 8))

BackupAsPDF(draw(hm,column_title=sprintf("%d proteins WGCNA input (no qnorm)", nrow(p.mat.f)),
           column_title_gp=grid::gpar(fontsize=16)), 'wgcna.input.', dimensions = c(9,12)) 
```
how many proteins have all cases? drop to 2.5k and only 770 of the DEG retained

```{r}
Heatmap(p.mat.f[complete.cases(p.mat.f),], cluster_rows = T, cluster_columns = F, na_col = 'grey', column_split = tstrsplit(colnames(p.mat.f), '_', keep=1), row_title=sprintf('%s proteins', nrow(p.mat.f[complete.cases(p.mat.f),])))

test <- p.mat.f[complete.cases(p.mat.f),]
sum(rownames(test) %in% sigProteins)

```

Ok, for input measurements,correct for batch & measure vs t0

```{r}
setorder(p.quant, receptor, Protein, timeStr)

p.quant[, batchControlled := LogIntensities - median(LogIntensities, na.rm = TRUE), by = .(Protein, receptor, SUBJECT)]
p.quant[, vsTimeZero := batchControlled - mean(batchControlled[timeStr == timeStr[!is.na(batchControlled)][1] ]), by = .(Protein, receptor)]

p.mat <- dcast(p.quant, Protein~GROUP+SUBJECT, value.var = 'vsTimeZero') %>%  as.matrix(rownames="Protein")


hm <- Heatmap(p.mat[rownames(p.mat) %in% rownames(p.mat.f),], cluster_rows = T, cluster_columns = F, na_col = 'darkgrey', column_split = tstrsplit(colnames(p.mat.f), '_', keep=1), row_title=sprintf('%s proteins', nrow(p.mat.f)), show_row_names = F, column_names_gp = gpar(fontsize=5), column_title_gp = gpar(fontsize = 8))


BackupAsPDF(draw(hm,column_title=sprintf("%d proteins WGCNA input vsT0 (no qnorm & batch corrected)", nrow(p.mat.f)),
           column_title_gp=grid::gpar(fontsize=16)), 'wgcna.input.vsT0', dimensions = c(9,12)) 
```

QC
----
Check sample clustering based on our input gene list 
One branch in particular seems to be very different (DOR grp on left, but these seem later timepoints so possibly good biological reason); 
maybe a round of tmp normalisation?

```{r}
p.mat <- p.mat[rownames(p.mat) %in% rownames(p.mat.f),]

#Group data in a dendogram to check outliers
sampleTree = hclust(dist(t(p.mat)), method = "average")


pdf(file = "./GPCR_WGCNA_data/sampleClustering.pdf", width = 12, height = 9); 
par(cex = 0.6)
par(mar = c(0,4,2,0))
plot(sampleTree, main = "Sample clustering", sub="", xlab="", cex.lab = 1.5, 
     cex.axis = 1.5, cex.main = 2)
#Plot a line showing the cut-off
abline(h = 56, col = "red") #This value of 31000 was chosen based on my data, you need to check the best value to your data

dev.off()
```

Now that we have looked at the samples, lets checkout the genes we have selected
```{r}
gsg <- goodSamplesGenes(t(p.mat))
summary(gsg)
gsg$allOK
```

All genes and samples look pretty good; proceed with network construction

## network construction

We will proceed with creating a signed network, simplify interpretative by considering directionality of gene expression

Transpose the matrix, pick a soft threshold (minimise weak connections), and plot
Can see even raising to a low power considerably improves fit, we want to optimise fit while also maintaining a high connectivity

We will pick a soft threshold of 2.. very low number but leads to a significant improvement in model fit.. suggests we have a god fit for the data

150 seems like a high mean connectivity.. will prob end up with few v large modules, but lets see
Can go back and increase power if many spurious correlations, 

```{r}
net.in <- t(p.mat)

s.thres <- data.table(pickSoftThreshold(net.in)$fitIndices)

s.thres %>%  
  ggplot(aes(x=Power, y=SFT.R.sq)) + 
  geom_point() +
  geom_hline(yintercept = 0.8, color='darkred') +
  labs(y="Scale Free Topology Model Fit, signed R^2") +
  theme_classic()

s.thres %>%  
  ggplot(aes(x=Power, y=mean.k.)) + 
  geom_point() +
  labs(y='Mean Connectivity') +
  theme_classic() 

s.thres

```
Creating adjacency matrix
Our network is signed; 0 anti-correlated,1 is strongly correlated

keeping soft power threshold at 2 for now. Lets check clustering output and then 
Adjusting to soft threshold of 4; too few clusters with large N members

```{r}
softPower = 4 #Chosen in the graphs before
adj.mat = adjacency(net.in, power = softPower, corFnc = 'bicor', type = "signed") #Calculating the adjacency matrix
#help(adjacency )

dim(adj.mat)
```

Define our topological overlap matrix

```{r}
TOM <- TOMsimilarity(adj.mat)
```
Heatmap of the topological overlap matrix (similarity scores 1-0)
View what our clusters look like.. lets see if we even have anything visually
With soft thres=2, looks like v large clusters with thousands of genes.. have increased soft thresholding to 3 to reduce spurious(??) correlations


I dont think these clusters look too promising, but lets run the analysis and see
```{r}
hm <- Heatmap(adj.mat[1:2000,1:2000], cluster_rows = T, cluster_columns=T, column_title = 'adjacency matrix', row_title=sprintf('%s proteins', nrow(p.mat.f)), show_row_names = F, show_column_names = F)
BackupAsPDF(hm, 'adj.mat.st4.')
Heatmap(TOM[1:2000,1:2000], cluster_rows = T, cluster_columns=T, column_title = 'TOM similiary', row_title=sprintf('%s proteins', nrow(p.mat.f)), show_row_names = F, show_column_names = F)
BackupAsPDF(hm, 'tom.mat.st4.')
```
## Module Identification
----

Perform hierarchical clustering of the TOM dissimiliarity measure to identify modules

```{r}
TOM.dissimilarity <- 1-TOM

#creating the dendrogram 
geneTree <- hclust(as.dist(TOM.dissimilarity), method = "average") 
#plotting the dendrogram
sizeGrWindow(12,9)
plot(geneTree, xlab="", sub="", main = "Gene clustering on TOM-based dissimilarity", 
labels = FALSE, hang = 0.04)
```
Use the cuttree dynamic function to cut the dendogram and Identify modules

```{r}
Modules <- cutreeDynamic(dendro = geneTree, distM = TOM.dissimilarity, deepSplit = 2, pamRespectsDendro = FALSE, minClusterSize = 30)
table(Modules)
```



```{r}


hm <- Heatmap (prot.mat, cluster_columns = FALSE, 
         #show_row_names = FALSE,
         name = "log2(intensity/\nmean(timeZero))",
         column_split = tstrsplit(colnames(prot.mat), "[_.]")[[1]],
         na_col = 'black',
         row_title =sprintf("%d Proteins with agonist dependent labeling",
                            nrow(prot.mat)),
         row_names_gp = gpar (fontsize= 1.5))

hm

colnames(prot.mat)
#BackupAsPDF(hm)

```
Try generate matrix of DEG proteins

```{r}
net.in <- t(prot.mat)

s.thres <- data.table(pickSoftThreshold(net.in)$fitIndices)
s.thres
s.thres %>%  
  ggplot(aes(x=Power, y=SFT.R.sq)) + 
  geom_point() +
  geom_hline(yintercept = 0.9, color='darkred') +
  labs(y="Scale Free Topology Model Fit, signed R^2") +
  theme_classic()

s.thres %>%  
  ggplot(aes(x=Power, y=mean.k.)) + 
  geom_point() +
  labs(y='Mean Connectivity') +
  theme_classic() 
```
Try adjacency mat w threshold 

```{r}
softPower = 5 #Chosen in the graphs before
adj.mat = adjacency(net.in, power = softPower, corFnc = 'bicor', type = "signed") #Calculating the adjacency matrix
#help(adjacency )
```

Define our topological overlap matrix

```{r}
TOM <- TOMsimilarity(adj.mat)
```
plots of DEG matricies
```{r}
hm <- Heatmap(adj.mat, cluster_rows = T, cluster_columns=T, column_title = 'adjacency matrix', row_title=sprintf('%s proteins', nrow(adj.mat)), show_row_names = F, show_column_names = F)
BackupAsPDF(hm, 'sig.prots.adj.mat.st5.')

Heatmap(TOM, cluster_rows = T, cluster_columns=T, column_title = 'TOM similiary', row_title=sprintf('%s proteins', nrow(TOM)), show_row_names = F, show_column_names = F)
BackupAsPDF(hm, 'sig.prots.tom.mat.st5.')
```
## Module Identification
----

Perform hierarchical clustering of the TOM dissimiliarity measure to identify modules

```{r}
TOM.dissimilarity <- 1-TOM

#creating the dendrogram 
geneTree <- hclust(as.dist(TOM.dissimilarity), method = "average") 
#plotting the dendrogram
sizeGrWindow(12,9)
plot(geneTree, xlab="", sub="", main = "Gene clustering on TOM-based dissimilarity", 
labels = FALSE, hang = 0.04)
```
```{r}
#detected six modules; want to correlate these 
Modules <- cutreeDynamic(dendro = geneTree, distM = TOM.dissimilarity, deepSplit = 4, pamRespectsDendro = FALSE, minClusterSize = 20)
table(Modules)
```

```{r}
Modules
# convert to char vector

modules.anno <- as.character(Modules)
modules.tom <- as.character(Modules)
```
Heatmap of the modules 
---
```{r}
col.pal <- randomcoloR::distinctColorPalette(length(unique(Modules)))

# add wgcna module annotation
row_ha <- rowAnnotation(wgcna.modules=modules.tom, col=list(wgcna.modules = c("1"=col.pal[1], '2'=col.pal[2], '3'=col.pal[3], '4'=col.pal[4], '5'=col.pal[5], '6'=col.pal[6])))

# add split order
split <- factor(modules.tom, levels=c('1','2','3','4','5','6'))
split
hm <- Heatmap(prot.mat, cluster_columns = FALSE, 
         #show_row_names = FALSE,
         split = split,
         right_annotation = row_ha,
         name = "log2(intensity/\nmean(timeZero))",
         column_split = tstrsplit(colnames(prot.mat), "[_.]")[[1]],
         na_col = 'darkgrey',
         row_title =sprintf("%d Proteins",
                            nrow(prot.mat)),
         row_names_gp = gpar (fontsize= 1),
         column_names_gp = gpar (fontsize= 3),
         cluster_row_slices = F,
         column_title_gp = gpar (fontsize= 7))

hm <- draw(hm, column_title="WGCNA clusters",
           column_title_gp=grid::gpar(fontsize=10))

BackupAsPDF(hm, 'heatmap.wgcna.modules.ordered')
```
write out the 
```{r}
clust.genes <- extractClustersfromHeatmap(hm, prot.mat) %>% rbindlist()

clust.genes[,.N, by=Cluster]

fwrite(clust.genes, './output/wgcna.clustergenes.tom.csv')
```

First check out module GO enrichment results before deciding to adjust
More interested in performance of the smaller modules

```{r}
# helper functions including script to extract heatmap genes
source("/Users/martingordon/Documents/utils/mg_utils/HelperFunctions.R")

clust.genes <- extractClustersfromHeatmap(hm, prot.mat) %>% rbindlist()

# change clusterID to factor and order
clust.genes[, Cluster := factor(Cluster, levels=c('cluster1', 'cluster2', 'cluster3', 'cluster4', 'cluster5', 'cluster6'))]

# load the GO table
gmt.go <- loadGmtFromBioconductor(ontology = "ALL", keyType = "SYMBOL")

# our background? only genes used for WGCNA analysis
universe <- rownames(prot.mat)


enrich.dt <- enricherOnGroups(clust.genes, groupColumns = 'Cluster', geneColumn = "GeneID", term2gene.gmt = gmt.go, universe = universe)
simp.enrich <- simplifyEnrichBySimilarUniverseMembership(enrichResultsTable = enrich.dt, gmt=gmt.go, groupColumn = 'Cluster')


ht <- enrichHeatmapBestPerGroup(simplifiedEnrichTable = enrich.dt, groupColumn = 'Cluster', topN = 10, title='GO enrichment WGCNA modules', 
                                  row_names_gp = gpar(fontsize = 7), column_names_gp= gpar(fontsize = 6), upperThreshold = 10, cluster_columns =F)

BackupAsPDF(ht, 'go.enrichment.wgcna.modules.ordered', dimensions=c(8,12))
```
30-08-23
----
Initial clustering looks pretty promising; clearly distinct GO enrichment terms and clustering patterns
Interested in cluster 2 & 1 in particular; adjust settings to split the clusters
Try
-option 1  use adj mat instead of TOM
- adjust min cluster size using the dynamic cut algorithm
- adjust softthresholding to 'break' apart further (try 8 & 14; 85% and 90% R^2)

First attempt; just take the adjacency matrix and identify the clusters (perhaps without the TOM neighbor reinforcement, this may return smaller clusters)

```{r}
# calculate distance
adj.diss <- 1-adj.mat
```


```{r}
#creating the dendrogram 
geneTree <- hclust(as.dist(adj.diss), method = "average") 
#plotting the dendrogram
sizeGrWindow(12,9)
plot(geneTree, xlab="", sub="", main = "Gene clustering on adjacency-based dissimilarity", 
labels = FALSE, hang = 0.04)
```
# now use dynamic cut to define the modules

adjusting dendo cutting settings to 'split' module 1; deepsplit1 & min cluster size=18;
now 1/3 of size, but not sure if these are forming distinct interesting clusters
if interesting things detected split further
```{r}
#detected six modules; want to correlate these 
Modules <- cutreeDynamic(dendro = geneTree, distM = adj.diss, deepSplit = 1, pamRespectsDendro = FALSE, minClusterSize = 18)
table(Modules)

# define module list for annotation
modules.adj <- as.character(Modules)
```

Heatmap of the modules 
---
```{r}
col.pal <- randomcoloR::distinctColorPalette(length(unique(Modules)))



# add split order
split <- factor(modules.adj, levels=c('1','2','3','4','5','6','7','8','9','10','11'))
#split <- factor(modules.tom, levels=c('1','2','3','4','5','6'))
split

chr = sample(paste0("chr", 1:20), nrow(prot.mat), replace = TRUE)
split_level = intersect(1:11, split)

# add wgcna module annotation
row_ha <- rowAnnotation(wgcna.modules.adj=modules.adj, 
                        wgcna.modules.tom=modules.tom,
                        
                        #set any annotaiton settings for CH 
                        annotation_legend_param = list(wgcna.modules.adj = list(
                       	ncol = 2, 
                       	at = split_level,
                       	title = "wgcna.modules.adj")),
                        #setting annotation cols
                        col=list(wgcna.modules.adj = c("1"=col.pal[1], '2'=col.pal[2], '3'=col.pal[3],
                                                       '4'=col.pal[4], '5'=col.pal[5], '6'=col.pal[6], 
                                                       '7'=col.pal[7], '8'=col.pal[8],'9'=col.pal[9], 
                                                       '10'=col.pal[10], '11'=col.pal[11]),
                            
                                 wgcna.modules.tom =c("1"='red', '2'='blue', '3'='green', '4'='orange', '5'='yellow', '6'='purple')
                                 ))

hm <- Heatmap(prot.mat, cluster_columns = FALSE, 
         #show_row_names = FALSE,
         split = split,
         right_annotation = row_ha,
         name = "log2(intensity/\nmean(timeZero))",
         column_split = tstrsplit(colnames(prot.mat), "[_.]")[[1]],
         na_col = 'darkgrey',
         row_title =sprintf("%d Proteins",
                            nrow(prot.mat)),
         row_names_gp = gpar (fontsize= 1),
         column_names_gp = gpar (fontsize= 3),
         cluster_row_slices = F,
         column_title_gp = gpar (fontsize= 7))

hm <- draw(hm, column_title="WGCNA clusters; adjacency mat",
           column_title_gp=grid::gpar(fontsize=10))

BackupAsPDF(hm, 'heatmap.wgcna.modules.adj.tom.mat',dimensions=c(8,16))
```
'clean' heatmap of the modules

```{r}
col.pal <- randomcoloR::distinctColorPalette(length(unique(Modules)))

col.pal <- c("#D57AC7","#8DDDE1","#A1E4AC","#6EE766","#CEDF5F","#DEC5D2","#85A693","#DBBB7C","#7D9AD6","#D96A6E","#A94FDD")  #"#999933" '#DDCC77' "grey"

 
# add split order
split <- factor(modules.adj, levels=c('1','2','3','4','5','6','7','8','9','10','11'))
#split <- factor(modules.tom, levels=c('1','2','3','4','5','6'))

split_level = intersect(1:11, split)

# add wgcna module annotation
row_ha <- rowAnnotation(modules=modules.adj, 
                        #set any annotaiton settings for CH 
                        annotation_legend_param = list(modules = list(
                       	ncol = 2, 
                       	at = split_level,
                       	title = "wgcna modules")),
                        #setting annotation cols
                        col=list(modules = c("1"=col.pal[1], '2'=col.pal[2], '3'=col.pal[3],
                                                       '4'=col.pal[4], '5'=col.pal[5], '6'=col.pal[6], 
                                                       '7'=col.pal[7], '8'=col.pal[8],'9'=col.pal[9], 
                                                       '10'=col.pal[10], '11'=col.pal[11])))

hm <- Heatmap(prot.mat, cluster_columns = FALSE, 
         #show_row_names = FALSE,
         split = split,
         right_annotation = row_ha,
         name = "log2(intensity/\nmean(timeZero))",
         column_split = tstrsplit(colnames(prot.mat), "[_.]")[[1]],
         na_col = 'darkgrey',
         row_title =sprintf("%d Proteins",
                            nrow(prot.mat)),
         row_names_gp = gpar (fontsize= 1),
         column_names_gp = gpar (fontsize= 3),
         cluster_row_slices = F,
         show_row_names = F,
         column_title_gp = gpar (fontsize= 9))

hm <- draw(hm, column_title="WGCNA clusters",
           column_title_gp=grid::gpar(fontsize=12))

BackupAsPDF(hm, 'heatmap.wgcna.modules.adj.clean')
```
Think maybe regenerate, add annotation of the top 5 GO terms per group, add a bar with their median enrichment 



First check out module GO enrichment results before deciding to adjust
More interested in performance of the smaller modules

```{r}
# helper functions including script to extract heatmap genes
source("/Users/martingordon/Documents/utils/mg_utils/HelperFunctions.R")

clust.genes <- extractClustersfromHeatmap(hm, prot.mat) %>% rbindlist()
clust.genes[,.N, by=Cluster]

# change clusterID to factor and order
clust.genes[, Cluster := factor(Cluster, levels=c('cluster1', 'cluster2', 'cluster3', 'cluster4', 'cluster5', 'cluster6','cluster7', 'cluster8', 'cluster9', 'cluster10', 'cluster11'))]

# load the GO table
gmt.go <- loadGmtFromBioconductor(ontology = "ALL", keyType = "SYMBOL")

# our background? only genes used for WGCNA analysis
universe <- rownames(prot.mat)

enrich.dt <- enricherOnGroups(clust.genes, groupColumns = 'Cluster', geneColumn = "GeneID", term2gene.gmt = gmt.go, universe = universe)
simp.enrich <- simplifyEnrichBySimilarUniverseMembership(enrichResultsTable = enrich.dt, gmt=gmt.go, groupColumn = 'Cluster')

#custom ordering
enrich.dt[, Cluster := factor(Cluster, levels=c('cluster1', 'cluster2', 'cluster3', 'cluster4', 'cluster5', 'cluster6','cluster7', 'cluster8', 'cluster9', 'cluster10', 'cluster11'))]

ht <- enrichHeatmapBestPerGroup(simplifiedEnrichTable = enrich.dt, groupColumn = 'Cluster', topN = 10, title='GO enrichment WGCNA modules; adjacency mat', 
                                  row_names_gp = gpar(fontsize = 7), column_names_gp= gpar(fontsize = 6), upperThreshold = 8, cluster_columns =F)

BackupAsPDF(ht, 'go.enrichment.wgcna.modules.adj.mat.ordered', dimensions=c(8,12))
```

Lets use wordclouds to highlight each of the clusters using the simplifyEnrichment package
take then enrichment results and match them to the cluster names
working but not producing what I want.. refune list of GO terms (take top 10 per cluster)

```{r}

simp.enrich$simplified

col.pal <- c("#D57AC7","#8DDDE1","#A1E4AC","#6EE766","#CEDF5F","#DEC5D2","#85A693","#DBBB7C","#7D9AD6","#D96A6E","#A94FDD")  #"#999933" '#DDCC77' "grey"

 
# add split order
split <- factor(modules.adj, levels=c('1','2','3','4','5','6','7','8','9','10','11'))
#split <- factor(modules.tom, levels=c('1','2','3','4','5','6'))

split_level = seq(1,11,by=1) %>%  as.factor()


#word cloud annotation 
go.wc <- enrich.dt

sd.cols <- c('Cluster', 'Description', 'p.adjust')

go.wc <- go.wc[order(p.adjust), head(.SD, n=30), .SDcols=sd.cols, by=Cluster] %>% 
  .[, .(Cluster, Description)] %>% 
  #collapse terms per cluster (using all terms atm)
  .[, GO.wc := paste(Description, collapse = ' '), by=Cluster] %>% 
  .[, name := as.factor(gsub('cluster', '', Cluster))] %>% 
  .[, .(name,GO.wc)] %>%  unique()

word.cloud <- go.wc$GO.wc
names(word.cloud) <- go.wc$name

word.cloud <- split(word.cloud, names(word.cloud))

# add wgcna module annotation
row_ha <- rowAnnotation(modules = modules.adj, 
                        wc = anno_word_cloud(split, word.cloud, fontsize_range = c(2)),
                        #set any annotaiton settings for CH 
                        annotation_legend_param = list(modules = list(
                       	ncol = 2, 
                       	at = split_level,
                       	title = "wgcna modules")),
                        #setting annotation cols
                        col=list(modules = c("1"=col.pal[1], '2'=col.pal[2], '3'=col.pal[3],
                                                       '4'=col.pal[4], '5'=col.pal[5], '6'=col.pal[6], 
                                                       '7'=col.pal[7], '8'=col.pal[8],'9'=col.pal[9], 
                                                       '10'=col.pal[10], '11'=col.pal[11])))


hm <- Heatmap(prot.mat, cluster_columns = FALSE, 
         #show_row_names = FALSE,
         split = split,
         right_annotation = row_ha,
         name = "log2(intensity/\nmean(timeZero))",
         column_split = tstrsplit(colnames(prot.mat), "[_.]")[[1]],
         na_col = 'darkgrey',
         row_title =sprintf("%d Proteins",
                            nrow(prot.mat)),
         row_names_gp = gpar (fontsize= 1),
         column_names_gp = gpar (fontsize= 3),
         cluster_row_slices = F,
         show_row_names = F,
         column_title_gp = gpar (fontsize= 6))

hm <- draw(hm, column_title="WGCNA clusters",
           column_title_gp=grid::gpar(fontsize=12))

BackupAsPDF(hm, 'heatmap.wgcna.modules.adj.clean.wordcloud', dimensions = c(10,12))



```
## 31-08-23
----
Generate linegraphs of the different clusters for each receptor
Generate linegraphs of the different receptors for each cluster

extract the genes from the clusters (do the same for the TOM data)

```{r}
# function in R snippets file ; requires ComplexHeatmap to be loaded
wgcna.clusters <- extractClustersfromHeatmap(hm, prot.mat) %>%  rbindlist()

wgcna.clusters[,.N, Cluster]
#fwrite(wgcna.clusters, './output/wgcna.clustergenes.adjmat.csv')

wgcna.clusters.adj <- fread('./output/wgcna.clustergenes.adjmat.csv')
#ran earlier
wgcna.cluster.tom <-  fread('./output/wgcna.clustergenes.tom.csv')
```

Now want to summarise the expression for each of these different clusters and plot the linecharts

Read in the expression file; plot both batch corrected and vs t0
```{r}
protQuant <- fread('data/2022_08_17_ProteinLevelData.lib.csv.gz')

group.noi <- protQuant[!GROUP %like% c("DOR|KOR|MOR|MRX2|MRX4|NK1R|NPFFR1|NPY1R|PTGER1|PTGER4|QRFPR|DOR"),unique(GROUP)]
group.noi

protQuant <- protQuant[!GROUP %in% group.noi, ]
protQuant <- protQuant[!GROUP %like% "MOR_LG94",]

protQuant[, `:=`(timeStr = str_extract(GROUP,'[0-9]{2}$'),
                 receptor = gsub("_[0-9]{2}$", '', protQuant$GROUP)
               )]

setorder(protQuant, receptor, Protein, timeStr)

protQuant[, batchControlled := LogIntensities - median(LogIntensities, na.rm = TRUE), by = .(Protein, receptor, SUBJECT)]
protQuant[, vsTimeZero := batchControlled - mean(batchControlled[timeStr == timeStr[!is.na(batchControlled)][1] ]), by = .(Protein, receptor)]
protQuant[, gene := multiUniprots2multiGenes(Protein)]

sigProteins <- unique(mss[receptor !=  "MOR.LG94"  & abs(log2FC) > log2(1.5) & pvalue < 0.005]$Protein)


```
FOr now just plot median intensities of each cluster
Try fix labels, but for now just ad to title
```{r}

# add cluster information
wgcna.protQuant <- protQuant[wgcna.clusters.adj, cluster:= i.Cluster, on=c(gene='GeneID')] %>%
  .[!is.na(cluster),]


# calculate average(median) expression per cluster receptor timepoint
wgcna.protQuant[, med.logInts := median(batchControlled), by=.(cluster, receptor, timeStr)]
# color palete

wgcna.protQuant[, GO.terms := fcase(cluster == 'cluster1', 'endosome',
                              cluster == 'cluster2', 'PM structure/adhesion',
                              cluster == 'cluster3', 'actin cytoskeleton',
                              cluster == 'cluster4', 'microtubule',
                              cluster == 'cluster5', 'plasma membrane',
                              cluster == 'cluster6', 'kinase activity',
                              cluster == 'cluster7', 'clathrin',
                              cluster == 'cluster8', 'peptide biosynthesis',
                              cluster == 'cluster9', 'actin polymerization',
                              cluster == 'cluster10', 'na',
                              cluster == 'cluster11', 'RNA processing'
                              )]

wgcna.protQuant[, cluster.go := paste0(cluster, ' (', GO.terms, ')')]

# create label dt for geom_text
labs.dt <- data.table(cluster= paste0('cluster', seq(1,11, by=1)))
# for now just add key words from GO terms to each of the clusters 
labs.dt[, GO.terms := fcase(cluster == 'cluster1', 'endosome',
                              cluster == 'cluster2', 'PM structure/adhesion',
                              cluster == 'cluster3', 'actin cytoskeleton',
                              cluster == 'cluster4', 'microtubule',
                              cluster == 'cluster5', 'plasma membrane',
                              cluster == 'cluster6', 'kinase activity',
                              cluster == 'cluster7', 'clathrin',
                              cluster == 'cluster8', 'peptide biosynthesis',
                              cluster == 'cluster9', 'actin polymerization',
                              cluster == 'cluster10', 'na',
                              cluster == 'cluster11', 'RNA processing'
                              )]


labs.dt
rColors <- randomcoloR::distinctColorPalette(length(unique(protQuant$receptor)))

# annotation of n cluster items
cluster.features <- wgcna.clusters[!is.na(Cluster), .N, by=Cluster]
cluster.features[,lab := paste0('n = ',N)]

levels(wgcna.protQuant$cluster)

str(wgcna.protQuant)
wgcna.protQuant$cluster <- factor(wgcna.protQuant$cluster, levels=c("cluster1","cluster2","cluster3","cluster4","cluster5","cluster6","cluster7","cluster8","cluster9","cluster10","cluster11"))


g <- ggplot(wgcna.protQuant[!cluster %in% c('cluster10','cluster5')], aes(x=timeStr, y=LogIntensities, group=receptor, color=receptor)) + 
  stat_summary(fun = "median", geom = "line") +
  scale_color_manual(values = rColors) + 
  ggtitle('cluster median expression') +
  labs(x='timepoint (mins)', y="Intensity (log2)") +
  facet_wrap(~cluster.go, scales='free_y', ncol=3) +
  theme_bw() +
  theme(
   strip.text = element_text(size = 6))

g

BackupAsPDF(g, 'wgcna.adj.cluster.median.expression.', dimensions = c(12,12))

#maybe add module average over all receptors
```

Now swap around and plot each receptor for each cluster (remove the uninteresting clusters (cluster 10))

```{r}

g <- ggplot(wgcna.protQuant[!cluster %in% c('cluster10','cluster5')], aes(x=timeStr, y=LogIntensities, group=cluster, color=cluster.go)) + 
  stat_summary(fun = "median", geom = "line") +
  #stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = .2) +
  scale_color_manual(values = rColors) + 
  ggtitle('receptor median expression') +
  labs(x='timepoint (mins)', y="Intensity (log2)") +
  facet_wrap(~receptor, scales='free_y', ncol=3) +
  theme_bw() +
  theme(
   strip.text = element_text(size = 6))

g

BackupAsPDF(g, 'wgcna.adj.receptor.median.expression.', dimensions = c(12,12))
```
Redo plots for vs T0 as this was used for the clustering and may look a little cleaner

```{r}
g <- ggplot(wgcna.protQuant[!cluster %in% c('cluster10','cluster5')], aes(x=timeStr, y=vsTimeZero, group=receptor, color=receptor)) + 
  stat_summary(fun = "median", geom = "line") +
  #stat_summary(fun.data = "median_cl_normal", geom = "errorbar", width = .2) +
  scale_color_manual(values = rColors) + 
  ggtitle('cluster median expression (vs T0)') +
  labs(x='timepoint (mins)', y="Intensity/mean(Time0)") +
  facet_wrap(~cluster.go, scales='free_y', ncol=3) +
  theme_bw() +
  theme(
   strip.text = element_text(size = 6))

g

BackupAsPDF(g, 'wgcna.adj.cluster.medianvsT0.expression.', dimensions=c(12,12))


g <- ggplot(wgcna.protQuant[!cluster %in% c('cluster10','cluster5')], aes(x=timeStr, y=vsTimeZero, group=cluster, color=cluster.go)) + 
  stat_summary(fun = "median", geom = "line") +
  #stat_summary(fun.data = "mean_cl_normal", geom = "errorbar", width = .2) +
  scale_color_manual(values = rColors) + 
  ggtitle('receptor median expression (vs T0)') +
  labs(x='timepoint (mins)', y="Intensity/mean(Time0)") +
  facet_wrap(~receptor, scales='free_y', ncol=3) +
  theme_bw() +
  theme(
   strip.text = element_text(size = 6))

g

BackupAsPDF(g, 'wgcna.adj.receptor.median.vsT0.expression.', dimensions=c(12,12))


```

correlate clusters with the predicted, IUPHAR and experimental scoring metrics
For now just use the median values per cluster for this vsT0 as what we used for the clustering

What values will we use? median log2FC for each cluster? place to start anyway

```{r}

wgcna.protQuant
wgcna.protQuant[, cluster.median := median(vsTimeZero, na.rm=T), by=.(cluster,timeStr)]
```








## unused
----

```{r}
col.pal <- c("#D57AC7","#8DDDE1","#A1E4AC","#6EE766","#CEDF5F","#DEC5D2","#85A693","#DBBB7C","#7D9AD6","#D96A6E","#A94FDD")  #"#999933" '#DDCC77' "grey"

 
# add split order
split <- factor(modules.adj, levels=c('1','2','3','4','5','6','7','8','9','10','11'))
#split <- factor(modules.tom, levels=c('1','2','3','4','5','6'))

split_level = intersect(1:11, split)

# add wgcna module annotation
row_ha <- rowAnnotation(modules=modules.adj, 
                        #set any annotaiton settings for CH 
                        annotation_legend_param = list(modules = list(
                       	ncol = 2, 
                       	at = split_level,
                       	title = "wgcna modules")),
                        #setting annotation cols
                        col=list(modules = c("1"=col.pal[1], '2'=col.pal[2], '3'=col.pal[3],
                                                       '4'=col.pal[4], '5'=col.pal[5], '6'=col.pal[6], 
                                                       '7'=col.pal[7], '8'=col.pal[8],'9'=col.pal[9], 
                                                       '10'=col.pal[10], '11'=col.pal[11])))

hm <- Heatmap(prot.mat, cluster_columns = FALSE, 
         #show_row_names = FALSE,
         split = split,
         right_annotation = row_ha,
         name = "log2(intensity/\nmean(timeZero))",
         column_split = tstrsplit(colnames(prot.mat), "[_.]")[[1]],
         na_col = 'darkgrey',
         row_title =sprintf("%d Proteins",
                            nrow(prot.mat)),
         row_names_gp = gpar (fontsize= 1),
         column_names_gp = gpar (fontsize= 3),
         cluster_row_slices = F,
         show_row_names = F,
         column_title_gp = gpar (fontsize= 9))

hm <- draw(hm, column_title="WGCNA clusters",
           column_title_gp=grid::gpar(fontsize=12))

BackupAsPDF(hm, 'heatmap.wgcna.modules.adj.clean')
```

Supplying adjacency matrix instead of TOM undefinitive; 
played with parameters, including cutdepth and recovered best results using deepSplit = 1, minClusterSize = 18 with adj.mat input 
min cluster size =20 produces some interesting clusters,  min size=30 did reduce cluster 1 size, but not performance increase expected...we also generated a lot of noise clusters
No simple way of splitting interesting cluster using adj.mat instead of tom

Alternative: try the k-module algorithm: (code below from paper) 
Essentially iteratively looks at degree of genes within the clusters and looks to reassign to clusters with more similar mean connectivity
Maintains the strong cluster signal we detected in larger clusters, but the smaller ones are not enriched for knwon bio function
https://www.mdpi.com/2073-4425/12/1/87



```{r}
# source("Kmodule.R")
# dynamicColors<-Kmodule(dynamicMods, adjacency, 100)

Kmodule<-function(dynamicMods, adjacency, MaxIterations){
nIteration=0 # iterations
continue.change=TRUE 
cluster.vector<-dynamicMods# Save the cluster(module) label for each gene
initialClusterColors=lastClusterColors=clusterColors = labels2colors(cluster.vector)# Save the cluster(module) Color for each gene
colorlevels=unique(clusterColors)
nCluster<-length(colorlevels) # The number of module 
nGenes<-length(clusterColors) # Number of genes
error.matrix<-matrix(0,nrow=nGenes,ncol=nCluster) # Record the average connectivity of each gene to each cluster(module)
colnames(error.matrix)<-colorlevels

while(continue.change){
  nChange=0
  nLastChange=0
  
  #  genes correlation for each module
  for (i in c(1:nCluster))
  {
    whichmodule=colorlevels[[i]];
    restrict1 = (clusterColors==whichmodule);
    Alldegrees1=intramodularConnectivity(adjacency, clusterColors)#calculating the intramodular connectivity for each gene
    nmodule<-length(which(restrict1==TRUE))  
    moduleLabel<-as.numeric(rownames(Alldegrees1)[restrict1])
    error.matrix[,i]<-rowSums(adjacency[,moduleLabel])/nmodule
    
  }
  error.matrix[, which(colorlevels=="grey")]=0 # The gene in gray module remains the same
  
  #Redefine the cluster(module) to which each gene belongs
  for (i in 1:nGenes){
    if(cluster.vector[i]!=0){   
      clusterColors[i]<-colorlevels[which.max(error.matrix[i, ])] 
    } 
    if(clusterColors[i] != initialClusterColors[i]){nChange<-nChange+1}
    if(clusterColors[i] != lastClusterColors[i]){nLastChange<-nLastChange+1} 
  }
  lastClusterColors<-clusterColors
  nIteration=nIteration+1
  continue.change=all(nIteration<MaxIterations & nLastChange>0) 
}
dynamicColors<-clusterColors
return(dynamicColors)
}


```

```{r}
dynamicColors <- Kmodule(Modules, TOM.dissimilarity, MaxIterations = 100)

# 8 modules detected; lets plot the heatmap and see
dynamicColors %>%  unique()
```

Now add this K-module output information
```{r}

# add wgcna module annotation
row_ha <- rowAnnotation(wgcna.modules.adj=modules.adj, 
                        wgcna.modules.tom=modules.tom,
                        wgcna.kmodules=dynamicColors,
                        col=list(wgcna.modules.adj = c("1"=col.pal[1], '2'=col.pal[2], '3'=col.pal[3], '4'=col.pal[4], '5'=col.pal[5], '6'=col.pal[6], '7'=col.pal[7], '8'=col.pal[8]),
                                 
                                 wgcna.modules.tom =c("1"='red', '2'='blue', '3'='green', '4'='orange', '5'='yellow', '6'='black'),
                                 wgcna.kmodules=c("turquoise"="turquoise","blue"='blue', 'yellow'='yellow', 'green'='green', 'red'='red', 'pink'='pink', 'black'='black', 'brown'='brown')
                                 ))


# add split order
#split <- factor(modules.tom, levels=c('1','2','3','4','5','6'))
split <- factor(dynamicColors)
#split <- factor(modules.adj)

hm <- Heatmap(prot.mat, cluster_columns = FALSE, 
         #show_row_names = FALSE,
         split = split,
         right_annotation = row_ha,
         name = "log2(intensity/\nmean(timeZero))",
         column_split = tstrsplit(colnames(prot.mat), "[_.]")[[1]],
         na_col = 'darkgrey',
         row_title =sprintf("%d Proteins",
                            nrow(prot.mat)),
         row_names_gp = gpar (fontsize= 1),
         column_names_gp = gpar (fontsize= 3),
         cluster_row_slices = F,
         column_title_gp = gpar (fontsize= 7))

hm <- draw(hm, column_title="WGCNA clusters; adjacency mat",
           column_title_gp=grid::gpar(fontsize=10))
```

lets enrich on the 
```{r}
clust.genes <- extractClustersfromHeatmap(hm, prot.mat) %>% rbindlist()

enrich.dt <- enricherOnGroups(clust.genes, groupColumns = 'Cluster', geneColumn = "GeneID", term2gene.gmt = gmt.go, universe = universe)
simp.enrich <- simplifyEnrichBySimilarUniverseMembership(enrichResultsTable = enrich.dt, gmt=gmt.go, groupColumn = 'Cluster')


ht <- enrichHeatmapBestPerGroup(simplifiedEnrichTable = enrich.dt, groupColumn = 'Cluster', topN = 10, title='GO enrichment WGCNA modules; adjacency mat', 
                                  row_names_gp = gpar(fontsize = 7), column_names_gp= gpar(fontsize = 6), upperThreshold = 10, cluster_columns =F)
```
Option2: adjust min cluster to the dynamic tree cut algorithm

```{r}
TOM.dissimilarity <- 1-TOM

#creating the dendrogram 
geneTree <- hclust(as.dist(TOM.dissimilarity), method = "average") 
#plotting the dendrogram
sizeGrWindow(12,9)
plot(geneTree, xlab="", sub="", main = "Gene clustering on TOM-based dissimilarity", 
labels = FALSE, hang = 0.04)
```

```{r}
#detected six modules; want to correlate these 
Modules.20 <- cutreeDynamic(dendro = geneTree, distM = TOM.dissimilarity, deepSplit = 4, pamRespectsDendro = FALSE, minClusterSize = 20)
Modules.10 <- cutreeDynamic(dendro = geneTree, distM = TOM.dissimilarity, deepSplit = 4, pamRespectsDendro = FALSE, minClusterSize = 10)

table(Modules.20)
table(Modules.10)
```
# outlook 
results so far suggest that further splitting the clusters using above params has improved module detection
look at the constructed network; further threshold to reduce spurious correlations, regen the network and look at our module stability

increase soft-thresholding to 8 to reduce influence of weaker correlations on the netwoek
```{r}
softPower = 14 #Chosen in the graphs before
adj.mat = adjacency(net.in, power = softPower, corFnc = 'bicor', type = "signed") #Calculating the adjacency matrix
#help(adjacency )
```


```{r}
TOM <- TOMsimilarity(adj.mat)
```
plots of DEG matricies
```{r}
hm <- Heatmap(adj.mat, cluster_rows = T, cluster_columns=T, column_title = 'adjacency matrix', row_title=sprintf('%s proteins', nrow(adj.mat)), show_row_names = F, show_column_names = F)
#BackupAsPDF(hm, 'sig.prots.adj.mat.st5.')
hm
Heatmap(TOM, cluster_rows = T, cluster_columns=T, column_title = 'TOM similiary', row_title=sprintf('%s proteins', nrow(TOM)), show_row_names = F, show_column_names = F)
#BackupAsPDF(hm, 'sig.prots.tom.mat.st5.')
```
```{r}
TOM.dissimilarity <- 1-TOM

adj.dissimilarity <- 1-adj.mat

#creating the dendrogram 
geneTree <- hclust(as.dist(adj.dissimilarity), method = "average") 
#plotting the dendrogram
sizeGrWindow(12,9)
plot(geneTree, xlab="", sub="", main = "Gene clustering on TOM-based dissimilarity", 
labels = FALSE, hang = 0.04)
```

```{r}
#detected six modules; want to correlate these 
tom.modules <- cutreeDynamic(dendro = geneTree, distM = TOM.dissimilarity, deepSplit = 4, pamRespectsDendro = FALSE, minClusterSize = 20)
table(tom.modules)

adj.modules <- cutreeDynamic(dendro = geneTree, distM = adj.dissimilarity, deepSplit = 3, pamRespectsDendro = FALSE, minClusterSize = 18)
table(adj.modules)
```


05/09/23
---
PCA plots of each cluster per receptor;

```{r}
wgcna.clusters <- fread('./output/wgcna.clustergenes.adjmat.csv')
```

Try generate the matrix with pearson cor and visualise
Lets also reduce n of features in the clustering

```{r}
# read in exp data
p.quant <- fread('data/2022_08_17_ProteinLevelData.lib.csv.gz')

# read in DEA results for filtering
mss <- fread('data/2022_08_31_NiceFitsPower3.csv')

p.quant$GROUP %>%  unique()
```
Inspect the raw data

```{r}

# fix the groups with an underscore in them MOR_LG and MOR_DAMGO to MOR.DAMGO
p.quant[, GROUP := gsub ("_([A-Z])", ".\\1", GROUP)]
# add some new identifier cols
p.quant[, `:=`(timeStr = str_extract(GROUP,'[0-9]{2}$'),
               receptor = gsub("_[0-9]{2}$", '', p.quant$GROUP)
               )]


group.noi <- p.quant[!GROUP %like% c("DOR|KOR|MOR|MRX2|MRX4|NK1R|NPFFR1|NPY1R|PTGER1|PTGER4|QRFPR|DOR"),unique(GROUP)]
group.noi

p.quant <- p.quant[!GROUP %in% group.noi, ]
p.quant <- p.quant[!GROUP %like% "MOR.LG94",]

p.quant$GROUP %>%  unique()
```

```{r}
p.quant[, batchControlled := LogIntensities - median(LogIntensities, na.rm = TRUE), by = .(Protein, receptor, SUBJECT)]
p.quant[, vsTimeZero := batchControlled - mean(batchControlled[timeStr == timeStr[!is.na(batchControlled)][1] ]), by = .(Protein, receptor)]
p.quant[, gene := multiUniprots2multiGenes(Protein)]
```

add cluster info to the expression dt
```{r}
p.quant.clust <- p.quant[wgcna.clusters, cluster := i.Cluster, on=c('gene' = 'GeneID')] %>% 
  .[!is.na(cluster),]
  
```

cluster comparison values; calculate median of min and max values over all TP per cluster
calculate median val per TP per cluster

```{r}
# min and max value across all timepoints per gene per receptor
p.quant.clust[, gene.min := min(vsTimeZero), by=.(gene, receptor)]
p.quant.clust[, gene.max := max(vsTimeZero), by=.(gene, receptor)]

# calculate median expression of min and max values ( i think this will be useful for lollipop chart)
p.quant.clust[, cluster.min.median := median(gene.min), by=.(cluster, receptor)]
p.quant.clust[, cluster.max.median := median(gene.max), by=.(cluster, receptor)]

#calculate median value per tp per cluster
p.quant.clust[, cluster.median.vsT0 := median(vsTimeZero), by=.(cluster, receptor, timeStr)]


p.quant.clust[, cluster.med.min := median(vsTimeZero), by=.(cluster, receptor)]
p.quant.clust[, cluster.receptor := paste0(cluster, '.', receptor)]

pca.in <- p.quant.clust %>% 
  .[, .(cluster, receptor, cluster.receptor, cluster.exp.vsT0)] %>% 
  unique() %>% 
  dcast(receptor~cluster, value.var='cluster.exp.vsT0') %>% 
  as.matrix(rownames='receptor')
  
```
PCA plot
```{r pca}


# now receptors in cols
pcaOut <- prcomp(pca.in)

colInfo <- data.table(colname = colnames(pca.in),
                      rowname = rownames(pca.in)
                      )

#PCA
pcaDT <- as.data.table(pcaOut$x, keep.rownames=TRUE)

pcaPercentVar <- round(100 * (pcaOut$sdev^2)/sum(pcaOut$sdev^2), 1)

pcaDT <- merge (pcaDT, colInfo, by.x = "rn", by.y = "colname", all.x = TRUE)
#plot first two components

p <- ggplot (pcaDT, aes(x=PC1, y=PC2,  fill = rn, color=rn)) + 
  geom_point(alpha=1.0, size=4) + 
  ggrepel::geom_text_repel(aes(label=rn), show.legend = FALSE, size = 3) +
  theme_bw() + 
  xlab (sprintf ("PC1, %.1f%%", pcaPercentVar[1])) + 
  ylab (sprintf ("PC2, %.1f%%", pcaPercentVar[2])) + 
  ggtitle ("receptor clustering (module median exps vs T0)" )+
  #scale_color_brewer(type = "qual", palette = "Dark2") +
  scale_shape_manual(values = 21:25) +
  guides(fill = guide_legend(override.aes = list(shape =21) ) ,#legend settings
         color = guide_legend(override.aes = list(shape =21) ) )

p

BackupAsPDF(p, 'PCA.receptor.module.profile')




# now receptors in cols
pcaOut <- prcomp(t(pca.in))


colInfo <- data.table(colname = colnames(pca.in),
                      rowname = rownames(pca.in)
                      )


pcaDT
#PCA
pcaDT <- as.data.table(pcaOut$x, keep.rownames=TRUE)

pcaPercentVar <- round(100 * (pcaOut$sdev^2)/sum(pcaOut$sdev^2), 1)

pcaDT <- merge (pcaDT, colInfo, by.x = "rn", by.y = "colname", all.x = TRUE)
#plot first two components

p <- ggplot (pcaDT, aes(x=PC1, y=PC2,  fill = rn, color=rn)) + 
  geom_point(alpha=1.0, size=4) + 
  ggrepel::geom_text_repel(aes(label=rn), show.legend = FALSE, size = 3) +
  theme_bw() + 
  xlab (sprintf ("PC1, %.1f%%", pcaPercentVar[1])) + 
  ylab (sprintf ("PC2, %.1f%%", pcaPercentVar[2])) + 
  ggtitle ("module clustering (median exps vs T0)" )+
  #scale_color_brewer(type = "qual", palette = "Dark2") +
  scale_shape_manual(values = 21:25) +
  guides(fill = guide_legend(override.aes = list(shape =21) ) ,#legend settings
         color = guide_legend(override.aes = list(shape =21) ) )

p

BackupAsPDF(p, 'PCA.module.profile')

```

radar chart;
try with the fmsb package
What we want is a radar plot per receptor for each of the clusters (and vice versa)
Could also try a lollipop chart (max and min vs T0 for each of the different cluster/receptor

```{r}
# want per receptor with each cluster
# using fmsb package

p.quant.clust

```


06/09/23
-----
Correlate with the IUPHAR classification

```{r}

pred <- fread("/Users/martingordon/Documents/projects/310723_QLi_GPCR.correlations/data/predictionScores.txt")
exp <- fread ("/Users/martingordon/Documents/projects/310723_QLi_GPCR.correlations/data/experimentalScores.txt")
iupar <- data.table(read_xlsx("/Users/martingordon/Documents/projects/310723_QLi_GPCR.correlations/data/IUPHAR_11GPCRs_Gprotein_class_primary.xlsx"))


exp.long <- melt(exp, id.vars = "GPCR", measure.vars = grep ("GNA", colnames(pred)), variable.name = "GProtein", value.name = "score")[, score := as.numeric(score)][]
pred.long <- melt(pred, id.vars = "GPCR", measure.vars = grep ("GNA", colnames(pred)), variable.name = "GProtein", value.name = "score")[, score := as.numeric(score)][]

# convert to long format
iupar.long <- melt(iupar, id.vars = 'GPCR', measure.vars = grep('GPCR', colnames(iupar), invert=T),  variable.name = "GProtein", value.name = "score") %>% 
  .[, score := as.numeric(score)] 

```

```{r scores.list}
scores.list <- list(exp = exp.long,
                    pred = pred.long,
                    iupar = iupar.long)
```

Convert the scores to a matrix

```{r}
scores.mat <- lapply(scores.list, function(x){
  dcast(x, GProtein~GPCR, value.var = 'score') %>% 
    as.matrix(rownames = 'GProtein')
})

```

change the  colnames to reflect the mss nomenclature

```{r}
scores.mat <- lapply(scores.mat, function(x){
  colnames(x) <- c("MRX2","MRX4","NPFFR1","NPY1R","DOR","KOR","MOR","PTGER1","PTGER4","QRFPR","NK1R")
  return(x)
})

```
take the max shift vs T0 per cluster per receptor
redo: not very good correlations, look at median value, maybe less dominated by outliers


First reorder the cols to follow above

```{r}
# read in mss results
mss.out <- fread("/Users/martingordon/Documents/projects/310723_QLi_GPCR.correlations//data/2022_08_31_NiceFitsPower3.csv")

exp.mat <- dcast(mss.out,gene~receptor, value.var = 'log2FC') %>% 
  .[, MOR.LG94 := NULL] %>% 
  as.matrix(rownames ='gene')


# filter to sig genes and reorder
sig.genes <- mss.out[pvalue < 0.05 & abs(log2FC) > log2(1.5) & receptor != 'MOR.LG94', unique(gene) ]
exp.mat <- exp.mat[rownames(exp.mat) %in% sig.genes,]

# renanme MOR DAMGO to MOR
colnames(exp.mat) <- c('DOR', 'KOR', 'MOR', 'MRX2', 'MRX4', 'NK1R', 'NPFFR1', 'NPY1R','PTGER1', 'PTGER4','QRFPR')

# reorder the cols to match the scoring mat
col.order <-  c("MRX2","MRX4","NPFFR1","NPY1R","DOR","KOR","MOR","PTGER1","PTGER4","QRFPR","NK1R")
exp.mat <- exp.mat[, col.order]

# sanity check; looks good
head(exp.mat)
lapply(scores.mat, colnames)
```

```{r}
wgcna.clusters <- fread('./output/wgcna.clustergenes.adjmat.csv')

# add cluster info
mss.out <- mss.out[wgcna.clusters, cluster := i.Cluster, on=c(gene = 'GeneID')] %>%  
  .[!is.na(cluster),]


# take the max log2FC value per cluster per receptor and correlate these
mss.out[, max.log2FC := max(log2FC, na.rm=T), by=.(cluster,receptor)]
mss.out[, median.log2FC := median(log2FC, na.rm=T), by=.(cluster,receptor)]

# now want a matrix of cluster/receptor combinations
clust.mat <- mss.out %>% 
  .[receptor != 'MOR.LG94', .(median.log2FC,cluster,receptor)] %>% 
  unique() %>% 
  dcast(receptor~cluster, value.var = 'median.log2FC')  %>% 
  as.matrix(rownames='receptor') %>% 
  t()


colnames(clust.mat) <- c('DOR', 'KOR', 'MOR', 'MRX2', 'MRX4', 'NK1R', 'NPFFR1', 'NPY1R','PTGER1', 'PTGER4','QRFPR')
clust.mat <- clust.mat[, col.order]

(clust.mat) %>%  t() %>%  head()

lapply(scores.mat, function(x) t(x) %>%  head())
```

with the maximum log2FC val per receptor/cluster, correlations were quite poor (max 0.6) but improved when taking median log2FC values per cluster
cluster 6 showed v strong correlation with GqG11 protein profile
save these results
```{r}

# correlate t with each
cor.list <- lapply(scores.mat, function(x){
  cor(t(clust.mat), t(x), use= "pairwise.complete.obs") # cluster by row, so keep rownames as receptor
})


cor.long <- lapply(cor.list, function(x){
  x <- melt(as.data.table(x, keep.rownames = TRUE), id.vars = "rn", variable.name  = "GProtein", value.name = "R")
  setnames(x, old = "rn", new = "cluster")
  return(x)
})


clust.mat
scores.mat$iupar
```
write out results first then try regenerate with maximum change from t0

```{r}
# cor table of IUPAR gene scores
cor.tab <- cor.long$iupar
cor.table <- dcast(cor.tab, cluster~GProtein, value.var = c("R"))
fwrite(cor.table, './output/cluster.cor.med.log2FC.iupar.csv') 


cor.tab <- cor.long$pred
cor.table <- dcast(cor.tab, cluster~GProtein, value.var = c("R"))
fwrite(cor.table, './data/cluster.cor.med.log2FC.predicted.csv') 

```


Regenerate the correlations using vT0 values (what we used for the clustering) and check for GProtein correlation
```{r}
protQuant <- fread('data/2022_08_17_ProteinLevelData.lib.csv.gz')

group.noi <- protQuant[!GROUP %like% c("DOR|KOR|MOR|MRX2|MRX4|NK1R|NPFFR1|NPY1R|PTGER1|PTGER4|QRFPR|DOR"),unique(GROUP)]
group.noi

protQuant <- protQuant[!GROUP %in% group.noi, ]
protQuant <- protQuant[!GROUP %like% "MOR_LG94",]

protQuant[, `:=`(timeStr = str_extract(GROUP,'[0-9]{2}$'),
                 receptor = gsub("_[0-9]{2}$", '', protQuant$GROUP)
               )]

setorder(protQuant, receptor, Protein, timeStr)

protQuant[, batchControlled := LogIntensities - median(LogIntensities, na.rm = TRUE), by = .(Protein, receptor, SUBJECT)]
protQuant[, vsTimeZero := batchControlled - mean(batchControlled[timeStr == timeStr[!is.na(batchControlled)][1] ]), by = .(Protein, receptor)]
protQuant[, gene := multiUniprots2multiGenes(Protein)]
```

subset the expression matrix to genes in the clusters and get matrix of max shift vs T0 per cluster,receptor 
max shift an issue due to noise in the clusters... what about max shift per gene in each cluster, then take the median vlaue of that?
maybe ask Ben

```{r}
protQuant[wgcna.clusters, cluster := i.Cluster, on=c(gene = 'GeneID')]

protQuant

prot.mat <- protQuant[!is.na(cluster),] %>% 
  # take the max shift from t0 per cluster per receptor
  #.[, med.shift := median(vsTimeZero, na.rm = T), by=.(cluster,receptor)] %>% 
  .[, .SD[, vsTimeZero[which.max(abs(vsTimeZero))]], by=.(cluster,receptor)] %>% # extract the max absolute shift vs T0 
  setnames( old=c('cluster', 'receptor', 'V1'), new = c('cluster', 'receptor', 'max.shift')) %>% 
  dcast(receptor~cluster, value.var = 'max.shift') %>% 
  as.matrix(rownames="receptor") %>% 
  t()
  
```

rename the receptors and reorder to match the scoring matrices

```{r}
colnames(prot.mat) <- c('DOR', 'KOR', 'MOR', 'MRX2', 'MRX4', 'NK1R', 'NPFFR1', 'NPY1R','PTGER1', 'PTGER4','QRFPR')
prot.mat <- prot.mat[, col.order]

prot.mat
```
rerun the correlations with median shift per cluster/receptor
cluster 6 and 9 associated with Gq/G11

```{r}
# correlate t with each
cor.list <- lapply(scores.mat, function(x){
  cor(t(prot.mat), t(x), use= "pairwise.complete.obs")
})

cor.long <- lapply(cor.list, function(x){
  x <- melt(as.data.table(x, keep.rownames = TRUE), id.vars = "rn", variable.name  = "GProtein", value.name = "R")
  setnames(x, old = "rn", new = "cluster")
  return(x)
})
```

Write out median shift per cluster, need to correct for other scoring, think it might actually improve the scores

```{r}
# cor table of IUPAR gene scores
cor.tab <- cor.long$iupar
cor.table <- dcast(cor.tab, cluster~GProtein, value.var = c("R"))
fwrite(cor.table, './output/cluster.cor.med.shiftvsT0.iupar.csv') 


cor.tab <- cor.long$pred
cor.table <- dcast(cor.tab, cluster~GProtein, value.var = c("R"))
fwrite(cor.table, './data/cluster.cor.med.shiftvsT0.predicted.csv') 
```


Thoughts
--- 
Need to rerun the wgcna and filter for missing values. Want only proteins present in 90% of data? maybe impute mean values for other members of group then
metric to use? max shift in expression vs t0 per receptor per clust (also try median)



```{r}



# min and max value across all timepoints per gene per receptor
p.quant.clust[, gene.min := min(vsTimeZero), by=.(gene, receptor)]
p.quant.clust[, gene.max := max(vsTimeZero), by=.(gene, receptor)]

# calculate median expression of min and max values ( i think this will be useful for lollipop chart)
p.quant.clust[, cluster.min.median := median(gene.min), by=.(cluster, receptor)]
p.quant.clust[, cluster.max.median := median(gene.max), by=.(cluster, receptor)]

#calculate median value per tp per cluster
p.quant.clust[, cluster.median.vsT0 := median(vsTimeZero), by=.(cluster, receptor, timeStr)]


p.quant.clust[, cluster.med.min := median(vsTimeZero), by=.(cluster, receptor)]
p.quant.clust[, cluster.receptor := paste0(cluster, '.', receptor)]

```


